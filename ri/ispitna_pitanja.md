# ISPITNA PITANJA

## `1` RaÄunarska inteligencija, definicija i paradigme

Intaligencija - moguÄ‡nost razumevanja i ostvarivanja koristi od razumevanja, ukljuÄuje kreativnost, veÅ¡tine, savesnost, emociju u intuiciju.  
Tjuringov test da li maÅ¡ina moÅ¾e da imitira ljudski mozak: maÅ¡ina i Äovek odgovaraju na pitanja, ako ne moÅ¾emo da napavimo razliku onda maÅ¡ina ima veÅ¡taÄku inteligenciju. To ukljuÄuje da maÅ¡ina moÅ¾e da daje pogreÅ¡ne odgovore kao Å¡to bi ih i Äovek dao.  
RaÄunarska inteligencija je podgrana veÅ¡taÄke intelignecije.  
RaÄunarska inteligencija (Computation nitelligence) je inspirisana konceptima iz prirode, koji se javljaju u dinamiÄkom okruÅ¾enju.  
Npr posmatrana jata ptica, kolonije mrava.  
RaÄunarska inteligencija izuÄava mehahnizme inteligentnog ponaÅ¡anja u sloÅ¾enim okruÅ¾enjima.
Mehanizmi koji mogu da uÄe, da se prilagoÄ‘avaju, uopÅ¡tavaju...

RI paradigme
- VeÅ¡taÄke neuronske mreÅ¾e (Artificial neural networks - ANN)
    - oponaÅ¡aju ljudski mozak
    - mreÅ¾a je izgraÄ‘ena od veeÅ¡taÄkih neurona
    - mreÅ¾a obiÄno sadrÅ¾i ulazni, izlatni i nula ili viÅ¡e srednjih slojeva
    - neuronske mreÅ¾e mogu biti jednoslojne, viÅ¡eslojne sa propagacijom unapred, temporalne i rekurentne, samoorganizujuÄ‡e, kombinovane mreÅ¾e
    - primenjuju se u medicini, prepoznavanju zvuka i slika, kontrola robota, klasifikacija podataka...
- Evolutivna izraÄunavanja (Evolutionary computation - EC)
    - imitiraju proces prirodne evolucije
    - osnovni koncept je da prilagoÄ‘enije jedinke preÅ¾ivljavaju a manje prilagoÄ‘ene izumiru
    -  koristi je populacija jedinki - hromozoma
    - iterativno se kroz generacije simulira evolucija
    - vrste evolutivnih izraÄunavanja su genetski algoritmi, genetsko programiranja, evolutivne strategije, diferencijalna evolucija, kulturalna evolucija, koevolucija
    - korissti se za reÅ¡avanje teÅ¡kih poblema kombinatorne (diskretne) i kontinualne (globalne) optimizacije, klasifikaciju podataka, klaster analiza, aproksimacija vremenskih serija...
- Inteligencija grupa (Swarm intelligence - SI)
    - ideja zasnovana na socijalnom ponaÅ¡anju nekih organiama - mrava, pÄela, ptica...
    - PSO - Particle swarm optimization, socijalno ponaÅ¡anje jata ptica
    - svaka jedinka jate prestavlja kandidata za reÅ¡enje postavljneog optimiacionog problema
    - pozicija u viÅ¡edimenzionom prostoru pretrage se moÅ¾e pretvoriti u reÅ¡enje posmatranog problema
    - jedinke koje u prostoru reÅ¡enja uzimaju boljju poziciju privlaÄe druge jedinke
- VeÅ¡taÄki imuni sistem (Artificila immune system - AIS)
- Rasplinuti (fazi) sistemi (Fuzzy systems - FS)
    - inspirisani prirodnim jezikom, nije sve crno-belo veÄ‡ ima i sivog
    - ideja je da element moÅ¾e da pripada skupu u odrerÄ‘eno procentu, nije samo pripada / ne pripada
    - zasnovana je na zakonitostima verovatnoÄ‡e i bazirana je na opaÅ¾anjima
    - primena: kontrolni sistemi, automatski menjaÄi, kontrola liftova, kuÄ‡ni ueÄ‘aju, kontrola saobraÄ‡ajne signalizacije...

Srodan termin CI je Soft computing koji podraumeva upotrebu viÅ¡estrukih CI paradigmi i verovatnosnih metoda.

---

## `2.` VeÅ¡taÄke neuronske mreÅ¾e, definicija, bioloÅ¡ki neuron, veÅ¡taÄki neuron.

VeÅ¡taÄke neuronske mreÅ¾e za zadatak imaju da imitiraju ljudski mozak. Za razliku od moga koji obavlja viÅ¡e poslova isotvremeno, neuronske mreÅ¾e obavljaju samo jedan.

BioloÅ¡ki neuron
![neuron](./imgs/bio_neuron.png)
-  neuroni su meÄ‘usobno povezani
- veza ide izmeÄ‘u aksona jednog neurona i dendrita drugog - veza se naziva sinapsa
- sinapsa nije fiziÄka veza veÄ‡ se pod odreÄ‘enim uslovima prenosi impuls/signal sa jedne strane na drugu
- signal se Å¡alje povremeno
- neuron moÅ¾e da suzbije ili pojaÄa jaÄinu signala

VeÅ¡taÄki neuron - Artificial Neuron  
![neuron](./imgs/neuron.png)
- model bioloÅ¡kog neurona
- AN prima signal od okruÅ¾enja ili drugog AN, a zatim ga prenosi povezanim AN
- hemijske veze se simuliraju funkcijama
- ulazni signali su promenljive ili vektori promenljivih
- postoje teÅ¾ine w koje se mnoÅ¾e sa ulaznim signalom, i te teÅ¾ine se uÄe
- sinapsu simulira aktivaciona funkcija koja prima skalarni proizvod wx
- vrednost aktivacione funckije uzima u obzir prag koji odluÄuje da li Ä‡e se signal poslati dalje
- izbor teÅ¾ina i aktivacione funkcije omoguÄ‡ava uÄenje
- veÅ¡taÄki neuron predstavlja jednostavan mehanizam uÄenja linearne funkcije

VeÅ¡taÄke neuronske mreÅ¾e - Arrtificial Neural Networks
- mreÅ¾e slojevito rasporeÄ‘enih veÅ¡taÄkih neurona
- ima ulazni i izlazni sloj, a izmeÄ‘u je nula ili viÅ¡e srediÅ¡njih slojeva
- koristi se a uÄenje sloÅ¾enih i nelinearnh funkcija
- ulazni sloj mogu Äiniti pikseli slike
- izlaz jednog neurona se propagira na sve neurone narednog sloja i tako redom...
- cilj je nauÄiti funkciju
- uspeh uÄenja zavisi od koliÄine ulaznih podataka

Vrste veÅ¡taÄkih neurronskih mreÅ¾a
- jednoslojne
- viÅ¡eslojne mreÅ¾e sa propagacijom napred
- temporalne i rekurentne mreÅ¾e
- samoorganizujuÄ‡e
- kombinovane mreÅ¾e

## `3.` Uvod u fazi sisteme i fazi skupove
- veÄ‡ina realnih situacija ne moÅ¾e da se prikaÅ¾e binarno, pripada / ne pripada skupu, nije crno/belo
- Lofti Zadeh (1965) - opisao ideju fazi skupova
- fazi skupovi su bazirani na pretpostavci da moÅ¾emo definisati stepen pripadnosti nekom skupu
- pripadnost skupa se definiÅ¡e nekom numeriÄkom vrednoÅ¡Ä‡u izmeÄ‘u 0 i 1
- Ako je X domen, a x iz X konkretna element tog domena, onda se fazi skup A opisuje funkcijom pripadnosti:
Î¼_A: X -> [0, 1]
- npr domen je visina, a mi definiÅ¡e u kolikom meri neka visina pripada skupu visokih, odnosno niskih ljudi
- fazi skpovi mogu iti dfinisani nad diskretnim ili realnim domenom
- Notacije za predstavljanje diskretnog fazi skupa:
1. Preko skupa ureÄ‘eniih parova: 
    - $A = \{(Î¼_A(x_i),x_i)|x_i âˆˆ X, i = 1, ... , n_x \}$
2. Preko "sume": 
    - $A = Î¼_A(x_1)/x_1 + Î¼_A(x_2)/x_2 + Â·Â·Â· + Î¼_A (x_nx)/x_nx$
    - ne podrazumeva stvarno sabiranje veÄ‡ samo u smislu zapisa

- Notacija za realn fazi skup se daje preko "integrala"
    - kao suma malopre, ovo je samo notacija
    - ![integral](./imgs/integral.png)

- Fazi funkcija pripadnosti skupu
    - ograniÄena imeÄ‘u 0 i 1
    - za svaki element domena je jednoÄlana
    - postoji viÅ¡e moguÄ‡ih naÄina definisanja

    - ![grafik](./imgs/graph1.png)
    - ![legend](./imgs/legend1.png)

- Neke standardne fazi funkcije  
![grafik](./imgs/fazi_funkcije.png)

---
## `4.` Fazi skupovne operacije

- jednoakost skupova
    - fazi skupovi su jednaki ako imaju isti domen i pritom za svaki element domena imaju istu funkciju pripdnosti
    - $Ğ=B$ akko $Î¼_A(x) = Î¼_B(x)$ za sve $x \in X$ 
    - ovo implicira da i elemetni koji nisu deo sistema imaju jednaku vrednost funkcije pripadnosti, 0

- podskupovi
    - skup A je podskup skupa B akko $Î¼_A(x) <= Î¼_B(x)$ za sve  $x \in X$ 
    - funkcija pripadnosti A je manje od funkcije pripadnosti B

- komplement
    - ako je $A^c$ komplement skupa A onda za sve $x \in X$  $Î¼_A(x) = 1 - Î¼_{A^C}(x)$
    - ne vaÅ¾i identitet kao u klasiÄnoj teoriji skupova da je $A^C \cap A = âˆ… $ i $A^C \cup A = X$

- presek
    - moÅ¾e da se definiÅ¡e na viÅ¡e naÄina, neki standardni su:
    - preko minimuma:
        - $Î¼_{A \cap B}(x) = min \{ Î¼_A(x), Î¼_B(x)\}, \forall x \in X$
    - preko proizvoda:
        - $Î¼_{A \cap B}(x) =  Î¼_A(x) * Î¼_B(x),  \forall x \in X$
    - proÄ‘emo kroz sve elemente domena i izraÄunamo vrednost funkcije pripadnosti elemenata u preseku po izabranoj formuli
    - efikasnije je proÄ‡i kroz elemente samo jednog skupa
    - svaki element dobija stepen pripadnost preseku
    - problem sa proizvodom je teÅ¾nja nuli, nakon nekoliko mnoÅ¾enja broja manjeg od 1 se sve viÅ¡e teÅ¾i nuli
    - definicija preko minimuma reÅ¡ava ovaj problem

- unija
    - moÅ¾e da se definiÅ¡e na viÅ¡e naÄina, neki standardni su:
    - preko maksimuma   
        - $Î¼_{A \cup B}(x) = max \{ Î¼_A(x), Î¼_B(x)\}, \forall x \in X$
    - preko sume i preseka
        - $Î¼_{A \cap B}(x) =  Î¼_A(x) + Î¼_B(x) - Î¼_A(x) * Î¼_B(x),  \forall x \in X$
    - sa sumom i presekom treba biti oprezan, jer funckaije pripadnosti teÅ¾i 1 Äak i ako su polazne funckije bliske 0

![grafik](./imgs/fazi_operacije.png)

- na x osi su stepenin u celsijusima
- na y osi su vrednosti funkcije pripadnosti
- na grafiku su dva fazi skupa
1. plava linija za toplo
2. crvena linija za vruÄ‡e
- gledamo pripadnost skupova nad isitim domenom
- jedna tacka domena moÅ¾e da pripada toplom i vruÄ‡em u odreÄ‘enoj meri
- kako fukcija za toplo opada funkcija za vruÄ‡e raste na desno

---
## `5.` Karakteristike fazi skupova.

- **Normalnost**
    - fazi skup je normalan ako ima bar jedan element koji pripada skupu sa stepenom 1
    - $\exists x \in A , Î¼_A(x) = 1$ ili
    - $sup_xÎ¼_A(x)=1$
    - ima visinu 1
- **Visina**
    - suprermum funkcije pripadnosti
    - $height(A) = sup_xÎ¼_A(x)$
- **PodrÅ¡ka**
    - skup svih elemenata koji imaju pripadnost veÄ‡u od 0
    - $support(A) = \{x \in X | Î¼_A(x) > 0\}$
    - stvarno pripada skupu bar u nekom delu
- **Jezgro**
    - skup elemenata koji pripadaju skupu sa stepenom 1
    - $core(A) = \{x \in X | Î¼_A(x) = 1\}$
    - elementi koji bi u klasiÄnoj logici sigurno bili u skupu
- **$\alpha$-rez** 
    - skup svih elemenata koj imaju pripadnost najmanje $\alpha$
    - $A_\alpha = \{x \in X | Î¼_A(x) \geq \alpha\}$
    - kao neka relativizacija jezgra za $\alpha=1$
- **Unimodularnost**
    - fazi skup je unimodalan ako njegova funkcija pripadnosti unimodalna
    - unimodalna funckija - ima smo jednu vrednost sa najveÄ‡om vrednoÅ¡Ä‡u
- **Kardinalnost**
    - u zavisnosti od tipa domena se definiÅ¡e na jedan od narednih naÄina
    - $card(A) = \sum_{x \in X} Î¼_A(x)$
    - $card(A) = \int_{x \in X} Î¼_A(x)dx$
    - sabiramo vrednosti funkcije pripadnosti svih elemenata domena
- **Normalizacija**
    - fazi skup se normalizuje tako Å¡to se funkcija pripadnosti podeli visinom fazi skupa
    - $normalized(A) = Î¼_A(x) / height(x)$
    - preslikavanje dovodi do toga da skup postaje normalan, tj ispunjava svojstvo normalnosti, vrednost funkcije ide od 0 do 1?? TODO
- **Komutativnost**
- **Asocijativnost**
- **Tranzitivnost**
- **Idempotencija**

---
## `6.` Fazi i verovatnoÄ‡a.

- fazi i verovatnoÄ‡a nisu povezani
- jedina sliÄnost je Å¡to oba termina referiÅ¡u na (ne)sigurnost dogaÄ‘aja
- verovatnoÄ‡a se vezuje za sluÄajan dogaÄ‘aj, a u fazi nema koncepta sluÄajnosti i neizvesnosti
    - nema predviÄ‘anja da li je neko visok, veÄ‡ samo koliko pripada skupu visokih ljudi
    - u fazi ne govorimo o sigurnosti da se neki dogaÄ‘aj desi, ne govorimo kolika je Å¡ansa da padne glava ili pismo
- fazi se vezuje za stepen istinitosti, stepen pripadnosti nekom skupu
- verovatnoÄ‡a se vezuje za moguÄ‡nost predviÄ‘anja nekog ishoda

---
## `7.` Fazi logika.
Primer zakljuÄivanja:  
- imamo dva fazi skupa - jedan meri visinu a drug atletizam
- definiÅ¡emo pravilo zakljuÄivanja nad jednim domenom
- $Î¼_{tall}(A)=0.9 Î¼_{athlete}(A)=0.8$
- $Î¼_{tall}(B)=0.9 Î¼_{athlete}(B)=0.5$
- znamo da je dobar koÅ¡arkaÅ¡ visok i dobar atleta, gledamo ko je bolji
- primenimo pravilo minimuma za presek
- $Î¼_{good player}(A)= min \{0.9, 0.8\} = 0.8$
- $Î¼_{good player}(B)= min \{0.9, 0.5\} = 0.5$
- zakljuÄujemo da je A bolji koÅ¡arkaÅ¡
- u realnim okolnostima su sloÅ¾enije zavisnosti

KljuÄni elementi su lingvistiÄke promenljive i fazi _if-then_ pravila zakljuÄivanja.

LingvsitiÄke (fazi) promenljve - Zadeh (1973)
- promenljive Äije su vrednosti reÄi prirodnog (neformalnog) jezika
- reÄ _tall_ je lingvistiÄka promenljiva
- tipovi lingvisitÄkih promenljivih:
    - kvantifikatori: sve, veÄ‡ina, mnogo, neki, nijedan...
    - promenljive za uÄestalost: ponekad, Äesto, uvek...
    - promenljive za Å¡ansu: moguÄ‡e, verovatno, sigurno

- modifikatori lingvistiÄkih promenljivih
    - dodatne reÄi koje pojaÄavaju ili slabe efekat
    - najÄeÅ¡Ä‡e pridevi, veoma, malo, srednje...
    - mogu se navesti u relaciji sa originalnom lingvistiÄkom promenljivom putem funkcija 
    - npr $Î¼_{very tall}(x)= Î¼_{tall}(x)^2$
        - ako neko pripada skupu visokih ljudi sa sigurnoÅ¡Ä‡u 0.9 onda prpada skupu veoma visokih ljudi sigurnoÅ¡Ä‡u 0.81
    - za slabljenje efekta se uglavnom koristi $Î¼_{very tall}(x)= Î¼_{tall}(x)^{1/p}$ $za$ $p>1$
- fazi pravila zakljuÄivanja
    - npr _if **age** is OLD then **speed** is SLOW_
    - premise - stvari koje moÅ¾emo da izmerimo, izvedene primenom sistema zakljuÄivanja
    - zakljuÄak je verodostojan koliko i premise
    - na osnovu premisa se donosi skup zakljuÄaka
    - iz spoljaÅ¡nosti se dobijaju vrednosti, njih provuÄemo kroz skup pravila i dobijamo neku upotrebljivu vrednost
    ![](imgs/starost_sporost.png)
    - pripadnost osobe od 70 godina starim osobama je 0.4
    - uzimamo stepen pripadnosti premise i seÄemo y osu
    - gledamo skup koji nam je interesantan, tj skup sporih ljudi
    - centar gravitacije u oblasti spore brzine ograniÄeno je sa 0.4 je 3
    - prema ovome Ä‡e brzina osobe od 70 godina biti 0.4
    - centar gravitacije nije jedini naÄina da se ovo odredi

---
## `8.` Fazi zakljuÄivanje.
### Memdanijev metod:
![](./imgs/mamdani.png)
- ulaz iz stvarnog sveta se fazifikuje, tj prevodi na jezik fazi logike
- sprovodi se sistem zakljuÄivanja i dobija se fazifikovan izlaz
- defazifikacijom se fazifikovan izlaz prevodi u neÅ¡to razumljivo

### Fazifikacija
- ulazni podaci (premise) se iz nefazi prevode u fazi reprezentaciju
- primeni se funkcija pripadnosti nad ulaznim podatkom, prepoznajemo stepen pripadnosti svakog elementa iz domena
- npr za osobu od 70 godina, povuÄemo presek i gledamo koja je pripadnost svakom skupu
- nad dobijenim vrednostima se dalje sprovodi proces zakljuÄivanja
- npr A i B su fazi skupovi nad domenom X
- proces fazifikacije prihvata elemente _a_ i _b_ iz domena X
- na izlazu proizvodi fazi skup tako Å¡to im dodeljuje stepene pripadnosti svakom o fazi skupova
    - $\{(Î¼_A(a), a),(Î¼_B(a), a), (Î¼_A(b), b), (Î¼_B(b), b)$

### Primena pravila zakljuÄivanja
- cilj je primeniti pavila zakljuÄivanja nad fazifikovanim ulazima
- na izlazu iz pravila zakljuÄivanja je fazifikovan izlaz za svako od pravila (u opÅ¡tem sluÄaju je viÅ¡e pravila)
- za svako pravilo se odreÄ‘uje stepen pripadnosti zakljuÄku
- Primer:
    - neka su A i B definisani nad domenim $X_1$, dok je fazi skup C definisan nad domenom $X_2$
    - dato je pravilo _if A is a and B is b thenn C is c_
    - na osnovu fazifikacije imamo $Î¼_A(a)$ i $Î¼_B(b)$
    - izraÄunamo stepen pripadnosti skupa premisa, tj da je a iz A a b iz B
        - $min\{Î¼_A(a), Î¼_B(b)\}$
- ovo se radi za svako pravilo zakljuÄivanja
- neka je $a_k$ stepen pravila zakljuÄivanja za k-to pravilo
- sledeÄ‡i korak je raÄunanje stepena pripadnosti zakljuÄku $c_i$
    - $Î²_i = max\{Î±_{ki}\}$, za svako pravilo k u kojem figuriÅ¡e $c_i$
- to znaÄi da je na izlazu iz zakljuÄivanja stepen pripadnosti za svaki od fazi skupova zakljuÄaka

### Defazifikacija
- praktiÄno izbacujemo neÅ¡to upotrebljivo na izlaz
- podrazumeva odreÄ‘ivanje lingvisitÄkih promenljivih za prethodno odreÄ‘ene stepene pripadnosti zakljuÄcima
- funkcija pripadnosti skupu
![](./imgs/defazi_fja.png)
    - treba odrediti lingvistiÄku promenljivu ako su na osnovu pravila doneti zakljuÄci:
    - $Î¼_{LI}=0.8$, $Î¼_{SI}=0.6$, $Î¼_{NC}=0.3$

Pristup zasnovan na raÄunanju centroide:
![](./imgs/centroida.png)
- nakon raÄunanja centroide se proÄita ona lingvistiÄka promenljiva koja joj odgovara prema nekom od sledeÄ‡ih pravila:
1. max-min - uzima se centroida ispod lingvisitÄke promenljive koja odgovara zakljuÄku sa nejviÅ¡im stepenom, LI ovde
    - uimamo onaj skup koji ima najveÄ‡i stepen pripadnosnti
    -  prethodnom uzmemo LI, naÄ‘emo centroide i proÄitamo   vrednost ispod njih
    - ![](./imgs/defazi_min_max.png)
2. UproseÄavanje - raÄuna se centroida a sve lingvisitÄke promenljive i na osnovu toga se odreÄ‘uje konaÄna lingvisitÄka promenljiva
    - tehnika koja uima u obzir sve podrÅ¾ane zakljuÄke
    - $(0.8 + 0.6 + 0.3)/3 = 0.57$
    - traÅ¾imo pripadnost samo skupu koji je od interesa, tj gledamo LI, SI i NC
    - ![](./imgs/defazi_uprosecavanje.png)
3. Skaliranje - funkcije pripadnosti se skaliraju prema dobijenim zakljuÄcima i nakon toga se raÄuna centroida
    - skaliramo skupove da uzmemo u obzir stepen pripadnosti skupovima
    - suptilna tehnika koja odgovara stvarnosti
    - ![](./imgs/defazi_skaliranje.png)
4. Isecanje - funkcije pripadnosti se seku na mestima koja odgovaraju zakljuÄcima i potom se raÄuna centroida
    - ![](./imgs/defazi_isecanje.png)

---
## `9.` Optimizacija, definicija, izazovi, kljuÄni pojmovi.
Optimiacija je oblast koja se dominanto bavi algoritmima pretrage, a Äiji je cilj pronaÄ‡i reÅ¡enje problema koje
1. maksimizuje ili minimizuje neku unapred definisanu funkciju
2. opciono zadovoljava neki skup ograniÄenja, ovim se redukuje skup moguÄ‡nosti, npr radimo samo sa parnim brojevim

### Izazovi:
- reÅ¡enje moÅ¾e biti predstavljeno kao kombinacija vrednosti iz razliÄitih domena
- ograniÄenja mogu biti nelinearna
- karakteristike problema mogu varirati tokom vremena, tj mogu da se menjaju ograniÄenja i funkcija cilja
- funkcija cilja moÅ¾e biti u _konfliktu_ sa ograniÄenjima

### KljuÄni pojmovi
- funkcija cilja: $f:S ğŸ ‚ R$ 
    - S je domen, a R je skup realnih brojeva
    - slika skupa moguÄ‡nosti u realne vrednosti
    - realna vrednsoti u koju se slika govori o kvalitetu reÅ¡enja
    - cilj je kvantifikovati kvalitet ponuÄ‘enog reÅ¡enja iz domena
- minimum od f je maksimum od -f
- nezavisne promenljive - skup vrednsti __x__ koje utiÄu na vrednost f, i za date vrednosti promenljivih funkcija ima vrensot f(x)
- skup ograniÄenja najÄeÅ¡Ä‡e predstavlja zavisnosti izmeÄ‘u nezavisni promenljivih
    - npr ograniÄenje da jedno zavisi od drugog, ograniÄenja mogu da redukuju domen, npr da je x parno ili neparno
- skup ograniÄenja moÅ¾e da ograniÄava i same nezavisne promenljive, npr na neki interval ili skup vrednosti

### Programiranje ograniÄenja
- Constraint programming
- bavi se problemima bez funkcije cilja koji treba da zadovolje neka ograniÄenja
- nije isto Å¡to i optimizacija jer nema funkciju cilja
    - kao kad bi kod problema dama kvantifikovali svaki raspored na neki naÄin, a nemamo te dodatne kvantifikacije
    - sat problem - problem zadovoljivosti iskazne formule, potrebno je naÄ‡i valuaciju koja zadovoljava vreme
- problem programiranja ograniÄenja moÅ¾emo reÅ¡avati optimizacionim algoritmima, ali obrnuto ne moÅ¾e
- fja cilja predstavlja zadovoljivost reÅ¡enja


### Tipovi optimuma
- globalni optimum - najbolje reÅ¡enja na Äitavom dopustivom skupu reÅ¡enja S
    - $f(x^*) < f(x), \forall x \in S$
    - moÅ¾e ih biti viÅ¡e ali da imaju iste vrednosti a da se razliku samo u poziciji
- jak lokalni optimum - najbolje reÅ¡enje u nekoj okolini $N \sube S$
    - $f(x^*_N) < f(x), \forall x \in N$
- slab lokalni optimum - jedno od najboljih reÅ¡enja u okolini $N \sube S$
    - $f(x^*_N) \le f(x), \forall x \in N$

![](./imgs/optimumi.png)

### Metode optimizacije
- traÅ¾e optimum u prostoru dopustivih reÅ¡enja, tj reÅ¡enje koje zadovoljava svak ograniÄenja, domenska i ekslplicitna
- nekad moÅ¾emo da izaÄ‘eo iz skupa dopustivih reÅ¡enja jer postoji moguÄ‡nost da se u blizini nedopustivog nalazi dobro dopustivo reÅ¡enje

Prema fokusu pretrage:
- Lokalne metode
    - ne mogu da naÄ‘u globalni optimum, eventulno da ubode ako imamo sreÄ‡e
    - gradijentne metode
    - obiÄno deterministiÄke
- Globalne metode
    - reÅ¡ava probleme globalne i kombinatorne optimizacije
    - imaju mehanizam kojim mogu da izbegnu zaglavljivanje u lokalnom optimumu
    - malo izaÄ‘e iz rutine, sluÄajno proba neko reÅ¡enje ne bi li naleteli na neÅ¡to bolje i izbegli zaglavljivanje
    - obiÄno viÅ¡e stohastiÄke

Metode prema pristupu pretrage
- StohastiÄke - ima nivo sluÄajnosti
- DeterministiÄke - jasan postupak

Ideja: ako su blizu lokalnog optimuma primeni neku metodu, npr prati gradijent, ako si zaglavljen u minimumu zapamti gde si bio i prebaci se negde nasumiÄno i proveri ima li tamo neko bolje reÅ¡enje, sluÄajni brojevi pomaÅ¾u odglavljivanju.

### JoÅ¡ neki vidovi postavke optimizacionih problema
1. problem sa viÅ¡estrukim optimumima
    - pronaÄ‡i sva reÅ¡enja koja su optimalna ili dovoljno blizu optimuma
    - npr dedukujemo gde je pritisak na taÄ ekranu
2. viÅ¡eciljna optimizacija
    - imamo viÅ¡e funkcija cilja pa je sloÅ¾enije urediti reÅ¡enja
    - hoÄ‡emo istovremeno da optimizujemo viÅ¡e funkcija cilja, ali je problem Å¡to je u jednoj taÄk viÅ¡ optimizovana jedna funkcija a u drugoj druga
    - npr hoÄ‡emo da stignrmo najbrÅ¾e moguÄ‡e a da ne potroÅ¡imo previÅ¡e goriva, da ne upadnemo u guÅ¾vu i da ne bude preskupo
3. DinamiÄka optimizacija
    - funkcija cilja se menja tokom vremena

### Domen prostora reÅ¡enja
1. Kombinatorna (diskretna) optimizacija
    - dopustiv skup vrednosti promenljivih je iz konaÄnog ili beskonaÄnog skupa celih brojeva, ili se moÅ¾e kodirati celim brojevima prebrojiv skup
    - specijani sluÄaj su problemi binarne optimizacije, npr problem pokrivenosi grana
2. Globalna (kotinualne) optimizacija
    - dopustiv skup vrednosti je iz domena realnih brojeva, npr $R^n$


---
## `10.` Optimizacija bez ograniÄenja, definicija, primer.
Formulacija problema: minimizovati $f(x), x =(x_1, x_2, ... , x_n), x \in S$
- npr pronaÄ‡i minimum funkcije $f(x,y)=x^2+y^2$ na domenu realnih brojeva
- moÅ¾emo koristiti standardne analitiÄke tehnike za reÅ¡avanje

![](./imgs/bez_ogranicenja1.png)
- unimodalna funkcija - ima jedan optimum
- lako se nalazi minimum
![](./imgs/bez_ogranicenja2.png)
- neÅ¡to kompleksniji pimer
- fitness landscape - prostor funkcije cilja
- vidi se promena funkcije cilja u zavisnoti od dopustivih vrednosti

---
## `11.` Optimizacija sa ograniÄenjima, definicija, slika sa objaÅ¡njenjem kljuÄnih pojmova, rad sa nedopustivim reÅ¡enjima.

OpÅ¡ta formula u sluÄaju ograniÄenja:
- minimizovati $f(x), x=(x_1, ... , x_{nx}), x \in S$ pri ograniÄenjima:
    - $g_m(x) \le 0, m=1, ... , n_g$
    - $h_m(x) = 0, m=n_g, ... , n_g+n_h$
    - funkcije mogu biti proizvoljne, nezgodnije je reÅ¡iti problem ako je nelinearna
    - jednakost se moÅ¾e svesti na dve nejednakosti
- Ovde pored domenskih ograniÄenja postoje i ograniÄenja zasnovana na jednakosti i/ili nejednakosti

![](./imgs/ogranicenja.png)
- ograniÄenja redukuju prostor pretrage
- infeasible space - nedopustiv prostor reÅ¡enja
- feasible space - dopustiv prostor reÅ¡enja
- kada redukujemo prostor reÅ¡enja ne moramo da ih proveravamo viÅ¡e, ali pri proveri moramo da proveravao da li je reÅ¡enje dopustivo
- objective functiona - funkcija koju posmatramo
- ograniÄenje nejednakosti

Rad sa nedopustivim reÅ¡enjima:
1. Odbaciti ih
    - jednostavno ali uglavnom nije dovoljno dobro
2. Dodeljivati penal
    - npr negativan faktor u sluÄaju maksimizacije ili pozitivan u sluÄaju minimizacije
    - kaÅ¾njavamo sluÄaj da uÄ‘e u nedopustiv prostor
    - to Å¡to ne odbacujemo reÅ¡enja omoguÄ‡ava fluidniju pretragu
    - moÅ¾da bi doÅ¡li do optimuma u jednom koraku da nismo odbacili zbog blizine nedopustivom reÅ¡enju
3. Svoditi na reÅ¡enje bez ograniÄenja pa ga posle konvertovati u reÅ¡enje koje poÅ¡tuje ograniÄenja
4. OdrÅ¾avanje dopustivosti samim dizajnom metoda
    - najÄeÅ¡Ä‡e
    - ne dozvolimo da uÄ‘e u skup nedopustivih reÅ¡enja
    - ako traÅ¾imo dopustivu permutaciju vodimo raÄuna da nemamo dva ista broja, npr samo zamenjujemo mesta
5. UreÄ‘ivati nedopustiva reÅ¡enja prema stepenu nedopustivosti
6. Popravljati nedopustiva reÅ¡enja

---
## `12.` Kombinatorna optimizacija i optimizacioni algoritmi
- minimizovati $f(x), x=(x_1, ... , x_{nx}), x \in S$ pri Äemu je S konaÄan ili beskonaÄan i diskretan
- TrgovaÄki putnik (TSP)
    - imamo skup C od m gradova i funkcija udaljenosti $d(c_i, c_j) \in N$ za svaki par gradova
    - pronaÄ‡i permutaciju $p: [1..m]ğŸ ‚[1..m]$ takvu da je ukupna suma udaljenosti grana koje prolaze obilaskom minimalna
    - matrica udaljenosti ne mora biti simetriÄna, mogu biti jednosmerne ulice npr
    - Å¾elimo Å¡to efikasnije da obiÄ‘emo sve gradove
    - veliÄina dopustivog skupa m!, jer je toliko dopustivih permutacija
    - algoritam grube sile je eksponencijalan
    - opÅ¡ti sluÄaj TSP bi bio nad proizvoljnim grafom
    - u opÅ¡tem sluÄaju bi najsigurnije reÅ¡enje bilo totalna enumeracija, tj gruba sila
    - ako pretpostavimo da se radi u Euklidkom prostoru, zbog vaÅ¾enja nejednakosti trougla moÅ¾e malo bolje, ali i dalje teÅ¡ko
    1. Gruba sila - generiÅ¡emo i proÄ‘emo kroz sve permutacije
    2. DinamiÄko programiranje - identiÄno prethodnom, samo imamo memoizaciju i Äuvamo meÄ‘urezultate, bolja sloÅ¾enost ali i dalje eksponencijalno
    3. aproksimativni algoritam
        - matematiÄki utvrdimo da vaÅ¾e neke pravilnosti
        - za TSP je utvrÄ‘eno da postoje dva aproksimativna algoritma
        - dobijeno reÅ¡enje Ä‡e najviÅ¡e dva puta loÅ¡ije od optimalnog i postoji teorema koja to dokazuje
        - imamo gornju granicu ali to nije najbolja granica kvaliteta
        - obiÄno aproksimativni algoritmi imaju bolju sloÅ¾enost

PoreÄ‘enje razliÄitih pristupa
- Gruba sila i dinamiÄko programiranje
    - loÅ¡i za veÄ‡e dimanzije problema, npr preko 50ak gradova
    - daju optimalno reÅ¡enje ako zavrÅ¡e 
- Aproksimativni pristup
    - jako efikasni uglavnom, linearni ili polinomijalni
    - reÅ¡enja loÅ¡ijeg kvaliteta
    - prednost je Å¡to znamo da reÅ¡enje ne moÅ¾e biti viÅ¡e od dva puta loÅ¡ije
- Metaheuristike
    - reÅ¡enje Ä‡e biti blisko optimalnom, ali ne garantuje da Ä‡e biti optimalno
    - vreme izvrÅ¡avanje Ä‡e biti razumno, i to moÅ¾emo da kontroliÅ¡emo
### Algoritmi pretrage
- metaheuristike pripadaju Å¡irokoj grupi algoritama pretrage
- opÅ¡ta formula algoritma pretrage
![](./imgs/pretraga.png)
- izaberemo neko polazno reÅ¡enje iz dopustivog skupa
- kriteijum zaustavljanja: stabilnost reÅ¡enja, fiksan broj iteracija...
- raÄunamo vrednost funkcija cilja u svakoj iteraciji
- izraÄunamo pravac i smer pretrage qt, moÅ¾e da se raÄuna na razliÄite naÄine, npr gradijent
- korak moÅ¾emo gledati kao pravac poverenja u smer kretanja pretrage, menja se po nekoj funkciji vremena
- naredno reÅ¡enje se aÅ¾urira u skladu sa korakom pretrage

Primer: problem pokirivaÄa grana Ävorovima, potskup skupa Ävorova takav da su sve grane incidentne sa bar jednim Ävorom iz skupa
- reÅ¡enje u koraku $x_t$
- 0101110 npr to su odabrani Ävorovi grafa
- graf definisan matricom relacije
- variramo bitove i gledamo poboljÅ¡anje
- u svako koraku menjamo po jednom bitu - ako se resenje poboljsa onda idemo u tom pravcu, mozemo da mejamo i po dva bita  
1101100  
0001100  
0111100  
...  
0101101  

### Ubacivanje sluÄajnosti u pretragu
- metaheuristike kombinuju lokalnu pretragu i sluÄajnost
- neÅ¡to izmeÄ‘u Monte Karlo simulacija i lokalne pretrage
- Monte Karlo generiÅ¡e sluÄajne promenljive, nusmiÄno generiÅ¡e vrednosti, ispituje vrednosti funkcije cilja i Äuva optimum
- nema garanciju kvaliteta, kad doÄ‘e do reÅ¡enja nema garanciju da je najbolje
- kada broj pokuÅ¡aja teÅ¾i beskonaÄno i reÅ¡enje teÅ¾i optimumu
- Las Vegas algoritmi su takoÄ‘e sluÄajni algoritmi
- efikasnost je problem - ne moÅ¾emo baÅ¡ beskonaÄno, ali ogrman broj pokuÅ¡aja

- lokalna pretraga vrlo brzo iskonvergira ka lokalnom optimumu, sklona zaglavljivanju ali efikasna
- Monte Karlo - dolazi do globalnog optiuma ali izuzeno neefikasno
- ova dva naÄina se kombinuju simuliranim kaljenjem

- algoritam koji koristi sluÄjanos i determinizam

- diversifikacija - Å¡etanje bez vraÄ‡anja na mesto gde smo bili - omogucava nepristrasan prolaz kroz skup moguÄ‡nosti
- loklanom pretragom vrsimo intenzifikaciju pretrage

- sluÄajno se pomerimo i time vrÅ¡imo diversifikaciju, a onda intenzivfikuj pretragu - tj naÄ‘emo lokalni optimum i saÄuvamo ga za kasnije poreÄ‘enje

- intenzifikacija prirodno dopunjuje diversifikaciju

- Monte Karlo moÅ¾e da izabere taÄku koja je jako blizu optmuma, a da ne naÄ‘e optimum

### Simulirano kaljenje
- u svakoj iteracji imamo promenu temperature
- inspirisano hlaÄ‘enjem vrelog gvoÅ¾Ä‘a, pri Äemu metal oÄvrsne
- iteacije menjaju temperturu kojoj je izloÅ¾en metal
- verovatnoÄ‡a prihvatanja reÅ¡enja je uslovljena postupkom hlaÄ‘enja metalne reÅ¡etke
- verovatnoÄ‡a prihvatanja reÅ¡enje postaje sve veÄ‡a
- vremenom gledamo hoÄ‡emo li prihavtiti reÅ¡enje ili ne
- verovatnoca prihvatanja postaje sve manja - metal oÄvrscava - ima sve manje prostora za diversifikaciju
- pojaÄava se intensifikcija a smanjuje diversifikacije

- single solution - metaheuristike bazirane na pojediniÄnom reÅ¡enju,
u svakoj iteraciji rade sa jednim reÅ¡enjem koji je aktuelni kandidat za optimum
- u svakoj narednoj iteraciji se menja to resenje
- populacione heuristike - rade sa populacijom reÅ¡enja, genetski algoritmi
![](./imgs/kaljenje.png)

---
## `13.` ViÅ¡eciljna optimizacija.
Problemi kod kojih je potrebno zadovoljiti viÅ¡e funkcija cilja (kriterijuma)
- Ekomonija - naÄ‡i portfolio sa maksimalnim prihodom i minimalnim rizikom
- Transportni poblem - maksimizovati iskoriÅ¡Ä‡enost ulice a minimizovati zaguÅ¡enje, troÅ¡kove rutiranja i sliÄno
- poboljÅ¡anje jedne funkcije cilja znaÄi pogorÅ¡anje druge funkcije cilja
- npr poveÄ‡anje stabilnosti mosta poveÄ‡ava i troÅ¡kove
- pravi se balans, tj kompromis, koncept nedominiranih reÅ¡enja

### Pristupi reÅ¡avanju
- pravljenje ponderisanih proseka odnosno agregacija
    - svaka funkcija cilja ima teÅ¾inu koja predstavlja njen znaÄaj
    - ovo se kasnije svodi na klasiÄnu jednociljnu optimizaciju
    - problem je odrediti teÅ¾ine
- pravljenje skupa Pareto-optimalnih reÅ¡enja
    - reÅ¡enje __x__ dominira nad reÅ¡enjem __y__ ako nijedna vrednost funkcije cilja od reÅ¡enja __y__ nije bolja od odgovarajuÄ‡e vrednosti funkcije cilja __y__
    - reÅ¡enje __x__ je Pareto-optimalno ako ne postoji nijedno drugo reÅ¡enje koje dominira nad njim
    - skup svih Pareto-optimalnih reÅ¡enja se naziva Pareto-optimalan skup
    - Pareto-optimalna povrÅ¡ predstavlja povrÅ¡ koju formiraju funkcije cilja kada se primene nad Pareto-optimalnim skupom reÅ¡enja
    - algoritmi pretrage koji mogu efikasno da pretraÅ¾uju Pareto-optimalnu povrÅ¡
    - populacione strategije koje iterativno poboljÅ¡avaju skup dobrih reÅ¡enja upotrebom svojstva dominacije

---
## `14.` Klase sloÅ¾enosti izraÄunavanja i reÅ¡avanje NP teÅ¡kih problema.

Algoritam - konaÄan spisak pravila Äijim praÄ‡enjem dolazimo do reÅ¡enja bilo kog partikularnog problema (instance problema) iz date klase, a praÄ‡enje pravila traje konaÄano mnogo koraka.  

Problem je odluÄiv ako daje odgovor da ili ne.

Problemi poput TSPa se mogu svesti na problem odluÄivanja. Npr pitamo se da li za konkretan TSP problem postoji reÅ¡enje sa troÅ¡kovima manjim od _C_, a na osnovu odgovora moÅ¾emo menjati granicu C. SvoÄ‘enje moÅ¾e biti veoma neefikasno.

### Polinomski problemi
Problem odluÄivanja pripada klasi P 
- ako **postoji algortiam** A za reÅ¡avanje tog problema
- i polinom _p(n)_ takav da A zavrÅ¡ava izvrÅ¡avanje za **ne viÅ¡e od p(n) koraka** za svaku instancu tog problema
- pri Äemu je **n dimenzija problema**

Polinomijalni algoritmi se smatraju efikasnim.  
Algoritme Äije vreme ne moÅ¾emo da ograniÄimo polinomom podrazumevano ograniÄavamo eksponencijalnom funkcijom $c^n, c>1$

### Eksponencijalno reÅ¡ivi problemi
Postoje problemi za koje je dokazano da ne mogu biti reÅ¡eni algoritmom brÅ¾im od eksponencijalnog
- podrazumeva se da su ovi problemi postavljeni kao problemi odluÄivanja (klasa  **EXPTIME**)
- npr problem evaluacije poteza u uopÅ¡tenom Å¡ahu, igri GO i sliÄno
- uopÅ¡tena varijante igre podrazumeva da je promenljive dimenzije
- npr pronalazenje skuppa svih razapinjuÄ‡ih stabala u kompletnom grafu sa n Ävorova. Zna se da je broj razapinjuÄ‡ih stabala $n^{n-2}$, pa bi se eksponencijalno vreme potroÅ¡ilo samo za prikaz rezultata.

### NedeterministiÄki polinomski problemi (NP)
- problemi za koje se ne zna da li postoji polinomski algoritam za njihovo reÅ¡avanje
- ako se za konkretno ponuÄ‘eo reÅ¡enje problema odluÄivanja moÅ¾e utvrditi da li je odgovor potvrdan u polinomijalnom broju koraka onda je u pitanju polinomijalni nedeterminsitiÄki problem
- npr TSP
    - reÅ¡enje je bilo koja permutacija gradova
    - broj C predstavlja troÅ¡ak
    - moÅ¾e se dati potvrdan ili odriÄan odgovor u polinomskom vremenu

### Redukcija (svoÄ‘enje) problema
- imamo dva problema odluÄivanja A1 i A2
- pp da se za A1 moÅ¾e konstruisati polinomski algoritam u kom se kao jedan od koraka pojavljuje algoritam za reÅ¡avanje A2
- ako je algoritam za reÅ¡avanje problema A2 polinomski onda i za A1 postoji polinomski algoritam
- kaÅ¾e se da se A1 **redukuje** na A2
    - ako se za svaki specijalni X problem A1
    - moÅ¾e u polinomskom vremenu pronaÄ‡i specijalan sluÄaj Y problema A2
    - takav da je problem X odgovor potvrdan akko je za Y odgovor potvrdan
- za reÅ¡avanje problema A1 koristimo reÅ¡avaÄ A2, pri Äemu transformisanje A1 u A2 ne treba da prelazi sloÅ¾enost A2
- A2 je teÅ¾i problem jer moÅ¾da za A1 postoji brÅ¾i algoritam
- pp da je A2 eksponencijalno, imamo polinomijalni pretvaraÄ A1 u A2 i obrnuto, to je sve zajedno eksponencijalno, a moÅ¾da postoji polinomijalni direktan algortiam za A1

### NP potpuni (kompletni) problemi
- problem je np kompletan ako za svoÄ‘enje bilo kog np problema na posmatrani problem postoji polinomski algoritam
- ako ne znamo teÅ¾inu nekog problema i ako neki np teÅ¾ak problem svedemo na taj, onda je taj posmatrani problem najmanje np teÅ¾ak
- svi problemi su najviÅ¡e teÅ¡ki kao algoritam na koji se redukuju
- ako za bilo koji NP kompletan problem pronaÄ‘emo polinomski algoritam time bi dokaali postojanje polinomskog algoritma za svaki NP problem, tj pokaalo i se N=NP

### NP teÅ¡ki problemi
- spominje se u kontekstu optimizacije
- problemi Äije su odluÄive vairjante NP potpuni problemi
- zapravo NP kompletni problemi u klasi problema odluÄivanja

### NaÄini reÅ¡avanja problema
- egzaktno reÅ¡avanje problema
    - postupci koji dovode do garantovano optimalnog reÅ¡enja ako zavrÅ¡e
    - polinomske probleme treba reÅ¡avati egzaktno
- pribliÅ¾no (aproksimativno) reÅ¡avanje
    - postupci koji Äak i kad zavrÅ¡e ne garantuju optimalnost
    - ovde spadaju (meta)heuristike i algoritmi sa garancijom kvaliteta
    - pribliÅ¾no treba reÅ¡avati samo ako je postoji polinomski postupak, tj pribliÅ¾no treba reÅ¡avati NP teÅ¡ke probleme


---
## `15.` Evolutivna izraÄunavanja - opÅ¡ti koncepti
- evolucija se moÅ¾e posmatrati **optimizacionim procesom** sa ciljem poboljÅ¡anja **prilagoÄ‘enosti** organizma (ili sistema) **dinamiÄkom i takmiÄarsko nastrojenom okruÅ¾enju**
- prirodni mehanizam koji za posledicu ima da se oragnizmi u prirodi prilagoÄ‘avaju sistemu u kom se nalaze, a loÅ¡e prilagoÄ‘ene vrste izumiru

- Domeni
    - hemijski - organiski i neorganski
    - kosmiÄki - evolucija zvezda u svemiru
    - bioloÅ¡ki
    - evolucija ljudskih tvorevina

- Lamarack (1744-1829) 
    - podrÅ¾ava teoriju nasleÄ‘ivanja steÄenih karakteristika poznatu veÄ‡ 2000 godina
    - **opovrgnuto**
    - npr imamo osobu visoku 180cm, igra koÅ¡arku pa se izduÅ¾i na 185cm, ta visina neÄ‡e biti nasledna
    - nema veze izmeÄ‘u fenotipa i genotipa
    - fenotip - osobine koje su se ostvarile
    - genotip - osobine zapisane u hromozomu

- Darwin (1809-1882)
    - teorije evolucije kroz proces **prirodne selekcije**

### Prirodna selekcija
- svaka jedinka se **takmiÄki** sa ostalima u cilju preÅ¾ivljavanja
- **najbolje** jedinke imaju veÄ‡u Å¡ansu da preÅ¾ive i ostave potomstvo, one imaju viÅ¡e vremena da ostave potomstvo
- one ÄeÅ¡Ä‡e prenose svoje gene, tj **karakteristike**
- vremenom ove **pogodne** karakteristike postaju dominantne u populaciji
- tokom stvaranja potomstva ulogu igraju i sluÄajni dogÄ‘aji:
    - ukrÅ¡tanje - bira se gen oca ili majke, ukrÅ¡taju se geni, suÅ¡tinski ne nastaje niÅ¡ta novo
    - mutacija - nasumiÄna izmena zbog spoljaÅ¡njih dogaÄ‘aja, uvode se nove informacije u sistem, npr ako imamo populaciju ljudi jedne boje oÄiju, da bi se boja promenila potrebno je da se desi mutacija na odreÄ‘enom genu
- nema garancije da Ä‡e dobro prilagoÄ‘ene jedinke ostaviti potomstvo, ni da loÅ¡e prilagoÄ‘ene neÄ‡e
- evolucija po prirodnoj selekciji se deÅ¡ava sporo

### Evolutivna iraÄunavanja
- imitiraju proces evolucije kroz
    - prirodnu selekciju
    - ukrÅ¡tanje
    - mutacija
    - ... 
- umesto organizama i njihove borbe za preÅ¾ivljavanjem, jedinke u populcijama, kodiraju reÅ¡enja nekog problema
- jedinka se kodira odreÄ‘ennim strukturama podataka, listama, nizovima...
- neka funkcija cilja kvantifikuje prilagoÄ‘enost jedinke
- nakon nekog vremena reÅ¡enje evoluira u smeru poboljÅ¡anja

### UopÅ¡teni evolutivni algoritmi
- evolutivni algoritmi traÅ¾e optimalna reÅ¡enja putem **stohastiÄke** pretrage nad **prostorom reÅ¡enja**
- jedinke (hromozomi) predstavljaju pojedinaÄne taÄke u prostoru reÅ¡enja
- genetski algoritmi su populacioni algoritmi - menja se cela populacija, u svakom momentu raspolaÅ¾emo populacijom jedinki, a pp da su ravnomerno razbacane po prostoru pretrage
- KljuÄni aspekti evolutivnih algoritama:
1. ReÅ¡enja se kodiraju u vidu hromozoma, npr niz celi brojeva koji predstavlja sekvencu gena
2. Fitnes funkcija koja ocenjuje kvalitet jedinke, malo prilagoÄ‘enija u nekim situacijama u odnosu na funkciju cilja
    - funkcija cilja direktno odgovara postavci problema, duÅ¾ina najkraÄ‡eg ciklusa npr
    - fitnes funkcija bi mogla da daje penale za nekorektan ciklus
3. Inicijalizacija poÄetnog skupa jedinki, tj poÄetnog reÅ¡enja
4. Operatori selekcije - biranja jedinki koje se reprodukuju
    - kada sprovodimo ukrÅ¡tanje ne biramo sve jedinke
    - fitnes funkcija poveÄ‡ava Å¡ansu odreÄ‘ene jedinke da ostavi potomstvo
5. Operatori ukrÅ¡tanja - naÄin stvaranja novih jedinki od postojeÄ‡ih

### Pseudokod
```
inicijalizuj broj generacija na t=0;
kreiraj i inicijaliuj n_x-dimenzionu populaciju C(0) od n_s jedinki;
while nije_zadovoljen_uslov_zaustavljanja do
    izraÄunaj fitnes funkciju f(x_i(t)) svake jedinke x_i(t);
    izvrÅ¡i ukrÅ¡tanje i fomriraj potomke;
    odaberi novu populaciju C(t+1);
    preÄ‘i u narednu generaciju, t=t+1;
end
```

### Evolutivni algoritmi
- Genetski algoritmi
    - evolucija nad linearnim genotipom, nizom
    - pogodno kada imamo problem koji se moÅ¾e formulisati linearno
- Genetsko programianje
    - evolucija nad stabloidnim genotipom, nelinearnim strukturama
    - raÄunarski programi se mogu evoluirati na ovaj naÄin
    - moÅ¾e reÅ¡avat probleme klasifikacije genetskim algoritmima
- Evolutivno programiranje
    - evolucija fenotipa, tj ponaÅ¡anja
    - kodiranje sekvence ponaÅ¡anja, ali ne nizovima
    - nema ukrÅ¡tanja
    - fitnes je relativan u odnosu na druge funkcije
    - nije inspirsano prirodom ali se dobro ponaÅ¡a u prakski
- Evolutivne strategije
    - evolucija evolucije = evolucija genotipa + evolucija parametara evolucije genotipa
    - neki vid metaevolucije
    - ne variramo samo genotip veÄ‡ i uslove okruÅ¾enja
    - kao da imamo razliÄita podneblja za evoluciju, jednu populaciju stavimo na Madagaskar a drugu na Antarktik
- Diferencijalna evolucija
    - kao standardni EA samo se mutacija bira iz unapred nepoznate sluÄajne raspodele - prilagoÄ‘ene populacije
    - biraju se vektori pomeraja koji su relativni u odnosu na ostale jedinke populacije
    - ne pravi se pp iz koje raspodele biramo sluÄajne brojeve
- Kulturna evolucija
    - evolucija kulture u populaciji - kulture prihvataju verovanja iz populacije, ali i utiÄu na populaciju srazmerno svojoj prilagoÄ‘enosti 
    - nije bioloÅ¡ka evolucija
- Koevolucija
    - evolucija i preÅ¾ivljavanje kroz saradnju i takmiÄenje, npr biljke i insekti (simbioza)


---
## `16.` Kodiranje reÅ¡enja evolutivnog algoritma, fitnes funkcija i inicijalna populacija.

### Kodiranje (reprezentacija) - hromozom
- hromozomi su saÄinjeni od molekula DNK
- nalaze se u jezgru Ä‡elije
- svaki hromozom je saÄinjen od velikog broja gena
- gen - jedinica nasleÄ‘ivanja
    - odreÄ‘uje anatomiju i fiziologiju organizma
    - kodira i kontroliÅ¡e proces izgradnje proteina
    - odreÄ‘en je svojom pozicijom - lokusom
- jedinka je saÄinjena od sekvence gena
- vrednost (sadrÅ¾aj) gena se zove genski alel
- u konteksu EA hromozomi predstvljaju reÅ¡enje problema, a pojedinaÄni geni su karakteristike reÅ¡enja
- odabir pogodnog kodiranja je kljuÄno za reÅ¡avanje problema
- kodiranje je najÄeÅ¡Ä‡e zasnovano na nizu vrednosti nekog tipa, osim u sluÄaju genetskog programiranja gde je kod nelinearan (stablo)
- klasiÄna reprezentacija bi bio binarni vektor fiksne duÅ¾ine, npr za grafove kod moÅ¾e biti zasnovan na nizu celih brojeva fiksne duÅ¾ine

Primeri:
1. naÄ‡i najmanji podskup Ävorova takav da svaka od grana grafa ima bar jedan kraj u tom podskupu
2. Problem trgovaÄkog putnika - traÅ¾i se Hamiltonov ciklus, krenemo iz jednog grada obiÄ‘emo sve ostale i vratimo se u poÄetni, a to po najmanjoj ceni, predstavlja se permutacijom Ävorova

- domen hromozoma i domen reÅ¡enja ne moraju da se poklapaju
- npr moÅ¾emo da koristimo niz realnh vrednosti za hromozom, a da reÅ¡enje bude binaran vektor, npr ako je veÄ‡e od 0.5 onda true, inaÄe false
- metoda elektromagnetizma - jedinke se biraju iz prostora [0,1], a vektor predstavlja njihovu poziciju u prostoru, onda se nad tim jedinkama mogu primenjivati operatori elektomagnetnog privlaÄenja
- iskazni problem se moÅ¾e reÅ¡avati tehnikama diskretizacije, radimo sa realnim vrednostima pa ih diskretizujemo

Primer: p-Median
- imamo teÅ¾inski graf, Å¾elimo da naÄ‘emo skup p izabranih Ävorova tako da je ukupna udeljenost od svih ostalih Ävorova minimalna
- kao da biramo lokaciju za supermarket, klijenti i supermarketi su validne lokacije, Å¾elimo da svaki klijent ima supermarket relativno blizu
- moÅ¾emo gleadti taÄke u ravni
- za rastojanje uzmemo euklidsko
- posmatramo kompletan graf, iz svake pozicije se moÅ¾e doÄ‡i do svake druge
- najjednostavnija reprezentacija je vektor realnih vrednosti
![](./imgs/k_median.png)

### Fitnes funkcija
- kvantifikuje karakteristike jedinke, tj njihovu prilagoÄ‘enost
- primenjuje se nad jedinkom
- obiÄno apsolutna mera kvaliteta jedinke, ali moÅ¾e biti i realativna u odnosu na druge jedinke
- obiÄno je jednaka funkciji cilja, ali ne nuÅ¾no
- u primeru k-median u ravni fitnes funkciju definiÅ¡emo na isti naÄin kao i funkciju cilja, a to je udalejnost svih taÄaka od najbliÅ¾e odabrane taÄke (najbliÅ¾eg supermarketa)

### Razvoj uporednog algoritma
- koristi se za validaciju predloÅ¾enog algoritma
- idealno je taj algoritam egzaktan, tj radi taÄno
- u sluÄaju NP teÅ¡kih problema dimenzija koju reÅ¡avamo uporednim algoritmom je oÄekivano malo
- drugi naÄin provere rezultata je poreÄ‘enje sa veÄ‡ posotjeÄ‡im reuzltatima iz literature
- uporedni algoritmi Äesto korsite istu funkciju cilja i kodiranje 
    - moÅ¾e se implementirati algoritam sluÄajne pretrage i sistematiÄne pretrage TODO

### Inicijalizacija reÅ¡enja
- stanardni pristup: inicijalna populacija se formira od nasumiÄno odabranih dopustivih reÅ¡enja
- u sluÄaju nedopustivih reÅ¡enja Ä‡e verovatno biti potrebna popravka
- sluÄajnost je dobra zbog boljeg pokrivanja skupa dopustivih reÅ¡enja
- dovoljno velik sluÄajni uzorak ima dobru reprezentativnost
- ako neki deo nije pokriven na poÄetku verovatno neÄ‡e biti obiÄ‘en ni kasnije
- alternativa su deterministiÄke metode, ako po teoriji ili iz iskustva znamo gde bi optimum mogao biti onda kreÄ‡emo odatle

- veliÄina metode se odreÄ‘uje empirijski za konkretnu metodu
- veÄ‡a populacija omoguÄ‡ava veÄ‡u _pokrivenost_ i poveÄ‡ava Å¡asnu za nalaÅ¾enje globalnog optimuma - **diversifikacija**
- mala populacija je efikasnjie i omoguÄ‡ava brÅ¾u konvergeniju ka lokalnom optimumu - **intenzifikacija**
![](./imgs/init_populacija.png)

---
## `17.` Operator selekcije kod evolutivnih algoritama i elitizam

### Selekcija
- proces izbora jedinki koje Ä‡e uÄestvovati u kreiranju naredne generacije
- naÄelna ideja je dati veÄ‡u Å¡ansu boljim reÅ¡enjima
- selekcioni pritisak (selection pressure) - vreme potrebno da se proizvede uniformna populacija jedinki, odnosno da najbolje jedinke ostave svoje gene svuda
    - Å¡to je veÄ‡i pritisak ovo Ä‡e se desiti ranije
    - kada doÄ‘emo u situaciju da su sve jednike sliÄne onda nema viÅ¡e prostora za istraÅ¾ivanje
    - mutacijama moÅ¾emo da se izvuÄemo iz ove pozicije
    - ne treba preterivati sa selekcionim pritiskom, ako je visok pritisak raznovrsnost gena se brÅ¾e smanjuje, pa dolazi do preuranjene konvergencije

### Pristupi selekciji
1. SluÄajna
    - svaka jedinka ima istu Å¡ansu
    - najniÅ¾i selekcioni pritisak
    - spora konvergencija
2. Proporcionalno
    - daje veÄ‡u Å¡ansu boljim jedinkama, na osnovu fitnesa
    - ![](./imgs/rulet_formula.png)
    - ruletksa selekcija je standardan naÄin implementacije ovog mehanizma
        - simulira upotrebu ruletskog toÄka
        - veliÄine podeoka su proporcionalne fitnesu podeoka
        - simulira se bacanje kuglice tako Å¡to se generiÅ¡e random broj i gleda se kom intervalu pripada

3. Turnirska selekcija
    - turnir izmeÄ‘u sluÄajnog podskupa jedinki
    - ako je podskup jednak populaciji onda je to **elitizam**
    - ako je podkup veliÄine 1 onda je to **sluÄajna strategija**
    - variranjem veliÄine podskupa se menja selekcioni pritisak
    - biramo uÄesnike turnira, pobeÄ‘uje onaj sa nejveÄ‡om funkcijom cilja

4. Rangovska selekcija
    - umesto vrednosti fitnes funkcije se koristi samo redni broj u ureÄ‘enju populacije
    - smanjuje se selekcioni pritisak jer se dobrim reÅ¡enjima relativizuje znaÄaj
    - kod fitnes baziranih selekcija se moÅ¾e desiti da jedinke u nekoj okolini imaju dosta blizak fitnes

### Elitizam
- tehnika koja spreÄava gubljenje dobrih jedinki
- iako su roditelji najverovatnije dobre jedinke, primenom ukrÅ¡tanja i mutacije se moÅ¾e izgbiti kvalitet jedinki
- ovih pristupom se nekoliko najboljih jedinki direktno prebacuje u narednu generaciju
- broj elitistiÄki odabranih jedinki ne sme biti preveliki, da ne bi bio veliki selekcioni pritiska, tj prebrza konvergencija

---
## `18.` Operator ukrÅ¡tanja, mutacije, kriterijumi zaustavljanja - ukratko

### UkrÅ¡tanje
- proces kreiranja novih jedinki - potomaka
- podrazumevano se koriste operatori
    - ukrÅ¡tanja - rekombinacija gena
    - sluÄajne mutacije - opciona promena nasumiÄnog gena

- jednopoziciono nasumiÄno ukrÅ¡anje
    - ![](./imgs/jednopozicioni.png)

### Mutacija
- omoguÄ‡ava ubacivanje novih informacija u sistem
- 1258 -> 1248
- ukrÅ¡tanje radi samo sa veÄ‡ postojeÄ‡im podacim

### Kriterijumi zaustavljanja
1. istek unapred fiksiranog broja iteracija
2. istek unapred fiksiranog vremena
3. kada nema unapreÄ‘enja u poslednjih P generacija
4. kada u poslednjih P generacija nema promen u genotipu
5. ako je naÄ‘eno prihvatljivo reÅ¡enje, ako znamo Å¡ta je prihvatljivo
6. kad se nagib fitnes funkcije viÅ¡e ne poveÄ‡ava, potrebno je pratiti kretanje fitnes funkcije kroz vreme

### UporeÄ‘ivanje reÅ¡enja
- reÅ¡enja za poreÄ‘enje se dobijaju:
    - algoritmom sluÄajne pretrage
    - evolutivnim algoritmom
    - egzaktnim algoritmom, na mapi neke dimenzije gde je moguÄ‡e izvrÅ¡iti

- pri poreÄ‘enju treba voditi raÄuna da bude fer
    - npr isti broj izvrÅ¡avanj fitnes funkcije
    - fer je da se evolutivni algoritam izvrÅ¡i 1000 puta sa 10 jedinki i da se sluÄajni algoritam izvrÅ¡i 10 000 puta
    - nije pametno porediti vreme izvrÅ¡avanja jer on zavisi od jaÄine raÄunara

---
## `19.` Genetski algoritmi - uvodni koncepti, kanonski genetksi algoritam

### Tehnike pretrage
![](./imgs/tehnike_pretrage.png)
- polazilo se od Monte Karlo simulacija ali nisu bile dovoljno uspeÅ¡ne
- sekvencijalne tehnike su jednonitne
- paralelne tehnike - viÅ¡enitne, distribuirani sistemi, ili izvrÅ¡avanje preko mreÅ¾e

### Genetski algoritmi
- Amerika 1970ih
- kljuÄni autori: J. Holland, K. DeJong, D. Goldberg
- primenjuje se na probleme u diskretnom domenu
- postoje ekstenzije za reÅ¡avanje problema u realnom domenu, ali oni moraju biti np kompletni
- Karkteristike
    - nije preterano brz kao i veÄ‡ina populacionih metaheuristika
    - dobra heuristika za reÅ¡avanje kombinatornih problema
    - dosta varijatni - razliÄiti mehanizmi ukrÅ¡tanja, mutacije
- **no free lunch teorema**: ni jedan algoritam ne dominira nekim drugim algoritmom, nije bolji u svakom sluÄaju od drugog

### Kanonski genetski algoritam (SGA)
- orignalni genetski algoritam je napravio John Holland 
- naziva se joÅ¡ i jednostavni (kanonski) GA ili SGA
- drugi genetski algoritmi se razlikuju u 
    - reprezenacijama - kodiranjima i dekodiranjima
    - mutacijama
    - ukrÅ¡tanju
    - selekciji
- Pseudokod:
```
inicijalizuj populaciju;
evaluiraj populaciju; // izraÄunavanje fitnesa hromozoma
while nije ispunjen uslov zavrÅ¡etka {
    odaberi roditelja za ukrÅ¡tanje;
    izvrÅ¡i ukrÅ¡tanje i mutaciju;
    evaluiraj populaciju;
}
```

- Elementi SGA  

| karakteristike GA | imeplementacija u SGA | 
|-----------|-------|
| reprezentacija | niz bitova |
| ukrÅ¡tanje | n-poziciono ili ravnomerno
| mutacija | izvrtanje bitova sa fiksnom verovatnoÄ‡om
| selekcija roditelja| fitnes-srazmerna, tj ruletska|
| selekcija preÅ¾ivelih | roditelji se potpnuno zamenjuju decom|
| specijalnost | fokus je na ukrÅ¡tanju, intenzifikacija pretrage |

### SGA reprezentacija
- fenotip - kako jedinka ostvaruje potencijal
- genotip - geni, ono Å¡to je zapisano
- ovde je fenotip direktna posledica genotipa
- problem u nekom prostoru moÅ¾emo pretvoriti u problem u binarnom prostoru veÄ‡e dimenzije
- prostor problema i metode ne moraju biti isti
- funckija kodiranja - ulazni problem konvertuje u prostor metode
- funkcija dekodiranja - na izlazu daje reÅ¡enje u prostoru problema
- ako su prostor metoda i problema jednaki onda je preslikavanje identitet
![](./imgs/kodiranje.png)

### UkrÅ¡tanje
1. odaberi roditelja u skupu za ukrÅ¡tanje, cela populacija je skup za ukrÅ¡tanje
2. promeÅ¡amo podskup odabrnih roditelja (Shuffle), bez ponavljanja
3. za svaki uzastopni par hromozoma se izvrÅ¡i ukrÅ¡tanje sa verovatnoÄ‡om $p_c$, ako se ne primeni onda se kopiraju roditelji, $p_c$ je obiÄno iz intervala [0.6, 0.9]
4. za svako dete se primenjuje mutacija sa verovatnoÄ‡om $p_m$  po svakom bitu nezavisno
5. zameni celu populaciju sa novodobijenom populacijom dece

### SGA operator ukrÅ¡tanja sa jednom taÄkom
- odabere se sluÄajna pozicija, manja od broja gena
- razdvoji svakog roditelja na dva dela po ovoj poziciji 
- kreiraj decu razmenom delova izmeÄ‘u roditelja

### SGA operator mutacije
- svaki gen (bit) se sa verovatnoÄ‡om $p_m$ invertuje
- $p_m$ - stopa mutacije
    - tipiÄno je izmeÄ‘u $1/veliÄina\_populacije$ i $1/duÅ¾ina\_hromozomaa$

### SGA operator selekcije
- ideja je da bolje jedinke imaju veÄ‡u Å¡ansu
- Å¡anse su srazmerne fitnesu
- implementacija: ruletski toÄak
    - dodelimo svakoj jedinki iseÄak toÄka
    - okreni toÄak n puta i izaberi n jedinki

### Mane
- previÅ¡e restriktivna reprezentacija
- mutacija i ukrÅ¡tanje su primenljivi samo na bitovske i celobroje reprezentacije, nije dovoljno fleksibilno
- selekcija osetljiva na sluÄaj kada populacija konvergira, tj bliske fitnes vrednosti
- generisanje populacije se moÅ¾e unaprediti tehnikom eksplicitnog preÅ¾ivljavanja

- koristan za baziÄno razumevanje genetskog algoritma
- dobar za poreÄ‘enje sofisticiranijih algoritama

---
## `20.` Ostali tipovi reprezentacije kod genetskih algoritama i mutacije nad njima

### Druge reprezentacije
- Grejovo kodiranje celih brojeva
    - binarni hromozmi
    - male promene genotipa prave i male promene fenotipa, za razliku od standardnog kodiranja
    - "glatkija" genotip-fenotip preslikavanje moÅ¾e da poboljÅ¡a GA
    - npr u obiÄnom kodiranju 15=0111 s 16=1000, totalna promena genotipa a mala promena fenotipa

- Å¡eme kodiranja bazirane na drugim reprezentacijama
- numeriÄke vrendnosti se kodiraju direktno kao
    - celi brojevi
    - realni brojevi u fiksnom zarezu
    - onda se i operatori dizajniraju tako da rade sa ovim tipovima, tj celim ili realnim brojevima

- direktna celobrojna reprezentacija
    - logiÄna reprezentacija pri obradi procesiranju slika npr
    - nekad vrednosti mogu biti kategoriÄke iz fiksnog skupa, npr {red, green, blue}
    - n-poziciono / ravnomerno ukrÅ¡tanje radi u ovim situacijama
    - binarna mutacija se mora proÅ¡iriti, ne moÅ¾e biti smo izvrtanje bitova
        - mutiranje u bliske (sliÄne) vrednosti
        - mutiranje u nasumiÄne vrednosti, tipiÄno za kategoriÄke promenljive

- kodiranje realnog domena
    - npr problem globalne optimiacije $f: R^n \rightarrow R$
    - primer: Ackley-eva funkcija, nezgodan prostor za pretragu, u 2D
    - ![](./imgs/ackley.png)

    - preslikavanje na niz bitova:
        - $z \in [x,y] \subseteq R$ predstavljeni kao niz bitova $\{a_1, ... , a_l\} \in \{0, 1\}^L$
        - $[x,y] \rightarrow \{0, 1\}^L$ mora biti inverzno, tj jedan fenotip za svaki genotip
        - $Ğ“ : \{0, 1\}^L\rightarrow [x,y]$ definiÅ¡e reprezentaciju
        - ![](./imgs/realno_preslikvanje.png)
        - samo $2^L$ vrednosti od moguÄ‡ih beskonaÄno je moguÄ‡e kodirati
        - L odreÄ‘uje preciznost reÅ¡enja
        - velika preciznost > dugaÄki hromozomi > spora evolucija

    - kodiranje moÅ¾e biti direktno uz doradu operatora

- Mutacije za diretktno realno kodiranje
    - opÅ¡ta Å¡ema za brojeve u fiksnom arezu
    - ![](./imgs/mutacija_realno.png)
    - ravnomerna mutacija
        - $x_i'$ se bira ranomerano iz [$LB_i$, $UB_i$]
    - analogno izvrtanju bitova binarnog koda ili nasumiÄnom mutiranju kod celih brojeva
    - ako bi invertovali bitove onda postoji opasnost da malim izmenama mnogo menjamo fenotip
    - neravnomerne mutacije
        - verovatnoÄ‡a mutacije moÅ¾e da se menja vremenom i pozicijom npr
        - standardan pristup je dodeljivanje sluÄajne devijacije svakoj promenljivoj, a zatim izvlaÄenje promenljivih i N(0, d)
        - standardna devijcija d kontroliÅ¡e udeo promena , npr 2/3 devijacija Ä‡e se nalaziti u opsegu (-d, +d)


- problemi zasnovani na permutacijama
    - objekti se organizuju u odgovarajuÄ‡em redosledu, npr problem sortiranja, problem trgovaÄkog putnika (TSP)...
    - ovakvi problemi se generalno izraÅ¾avaju permutacijama
    - ako postoji n promenljivih, onda je reprezentacija saÄinjena od n celih brojeva takvih da se svaki pojavljuje taÄno jednom

- mutacije nad permutacijama
    - normalni operatori mutacije bi doveli do nedopustivih reÅ¡enja, neka vrednost bi se pojavila viÅ¡e puta a neka bi nestala
    - vrednsoti se moraju menjati bar dvema promenljivama
    - verovtnoÄ‡a mutacije sada opisuje vrednost promena operatora nad celim reÅ¡enjme, a ne nad pojedinaÄnim pozicijama
    - pitanje je koliko ekstraman efekat Å¾elimo na permutacija ima
    1. naÄin - izaberemo dve pozicije, alel sa druge pozicije se pomeri pored onog sa prve, dok se ostali ispomeraju
        - 1**2**34**5**6789 > 1**25**346789
        - ovim se zadrÅ¾ava veÄ‡i deo ureÄ‘enja onosno informacije o prethodnom susedstvu, Å¡to je dobro jer ne Å¾elimo previÅ¡e dramatiÄne promene
    2. mutacije zasnovane na zameni
        - odaberu se sluÄajno dve pozicije i zamene mesta
        - zadrÅ¾ava se veÄ‡ina ureÄ‘enja
        - 1**2**34**5**6789 > 1**5**34**2**6789 
        - manje intenzivna promena
    3. mutaciije zasnovane na inverziji
        - sluÄajno se izaberu dve pozicije pa se vrednosti izmeÄ‘u njih obrnu
        - 1**2345**6789 > 1**5432**6789 
        - intenzivnija promena ureÄ‘enja od prethodna dva
    4. mutacije zasnovane na meÅ¡anju
        - izabere se podskup pozicija na sluÄajan naÄin, pa se vrednosti na tim pozicijama sluÄajno reorganizuju
        - 1**2345**6789 > 1**3542**6789 
        - pozicije ne moraju biti uzastopne

---
## `21.` Ostali operatori ukrÅ¡tanja kod genetski algoritama

- jednopoziciono ukrÅ¡tanje
    - kvalitet zavisi od redosleda promenljivih u reÅ¡enju
    - geni sa razliÄitih krajeva hromozoma se nikad neÄ‡e naÄ‡i u istom potomku
    - ovo je poziciona pristrasnost, a nju ne Å¾elimo
    - moÅ¾e biti korisno ukoliko znamo strukturu problema, ali u opÅ¡em sluÄaju nepoÅ¾eljno

- n-poziciono ukrÅ¡tanje
    - bira se n sluÄajnih pozicija
    - razdvoji se po tim pozicijama
    - alternirajuÄ‡i delovi se spajaju
    - uopÅ¡tenje jednopozicionog ukrÅ¡tanja, a poziciona pristrasnost i dalje postoji
    - ako je n parno onda uvek zavrÅ¡avaju krajnji delovi u istom potomku, a ako je neparno onda zavrÅ¡avaju u razliÄitim potomcima

- ravnomerno ukrÅ¡tanje
    - kao bacanje novÄiÄ‡a za svaki gen, ako padne _glava_ ide u jednog potomka a za _pismo_ ide u drugog potomka
    - drugo dete je inverz prvog
    - nasleÄ‘ivanje je nezavisno od pozicije

### UkrÅ¡tanje ili mutacija?
- pitanje nekoliko decenija
- od problema zavisi Å¡ta je bolje
- najbolje oba
- bez mutacije bi se zagljavljivali u lokalnim ekstrmumima, reÅ¡enje bi zavisilo od polaznog reÅ¡enja, a radili bi samo kombinovanje postojeÄ‡ih vrednosti
- kad bi imali samo mutaciji iÅ¡li bi previÅ¡e nasumiÄno i teÅ¡ko bi konvergiralo
- samo ukrÅ¡tanje ne bi radilo, dok same mutacije bi
- eksploracija - otkrivanje novih oblasti u prostoru pretrage
    - mutacije
    - uvodi novu informaciju i time proÅ¡iruje prostor pretrage
    - mutacija vrÅ¡i u eksploataciju jer gleda lokalnu okolinu trenutnog reÅ¡enja
- eksploatacija - optimizacija u okviru postojeÄ‡ih oblasti (kombinovanje reÅ¡enja)
    - ukrÅ¡tanje je radi
    - pravi kombinaciju roditeljskih hromozoma
    - ako alel za globalni optimum ne postoji onda globalno reÅ¡enje nikad neÄ‡e biti dostignuto
- postoji kooperacija i konkurencija izmeÄ‘u njih
- da bi pogodili optimum obiÄno je potrebna sreÄ‡na mutacija
- ukrÅ¡tanjem se ne menja frekvencija genski alela, ako imamo 50% nula na prvom bitu posle n ukrÅ¡tanje Ä‡emo imati isto?%  TODO

### UkrÅ¡tanje za direktno realno kodiranje
- kod diskretnog domena (binarni ili celobrojni)
    - svaki alel dete z je direktno nasleÄ‘en od nekog od roditelja (x,y) sa jednakom verovatnoÄ‡om: $z_i = x_i \ or\ y_i$ 
    - nema smisla koristii n-poziciono ili ravnomerno, treba smisliti genotipsku reprezentaciju koja Ä‡e se svesti na fenotipsku
    - treba formirati decu koja su imeÄ‘u roditelja, tzv AritmetiÄko ukrÅ¡tanje
    - $z_i= \alpha x_i + (1-\alpha)y_i$, gde je $\alpha : 0 \le \alpha \le 1$
    - dete je linearna kombinacija roditelja
    - parametar $\alpha$ moÅ¾e biti
        - konstanta, za ravnomerno aritmetiÄko ukrÅ¡tanje
        - promenljiva, npr da zavisi od starosti populacije
        - odabrana sluÄajno svaki put

- jednostruko aritmetiÄko ukrÅ¡tanje
    - roditelji $<x_1, ... , x_n>$ i $<y_1, ... , y_n>$
    - sluÄajno se odabere gen k
    - ![](./imgs/aritmetic_ukrstanje.png)
    - efekat je neki vid uproseÄavanja, pravi se podesivi prosek

- jednostavno aritmetiÄko ukrÅ¡tanje
    - roditelji $<x_1, ... , x_n>$ i $<y_1, ... , y_n>$
    - sluÄajno se odabere gen k
    - ukrÅ¡tanje na nekom segmenut
    - ![](./imgs/jednostavno_ukrstanje.png)
    
- celovito aritmetiÄko ukrÅ¡tanje
    - najÄeÅ¡Ä‡e se koristi
    - zadrÅ¾ava se 1 dete, a imamo duplo viÅ¡e ukrÅ¡tanja
    - roditelji $<x_1, ... , x_n>$ i $<y_1, ... , y_n>$
    - ovde jedinke nemaju veliki diverzitet pa je potrban veÄ‡i stepen mutaciije
    - npr za $\alpha = 0.5$
    - ![](./imgs/celovito_ukrstanje.png)
    
###  UkrÅ¡tanje u permutacionim problemima
- obiÄni operatori ukrÅ¡tanja dovode do nedopustivih reÅ¡enja:
- ![](./imgs/nedopustivo.png)
- ukrÅ¡tanje prvog reda
    - ideja zadrÅ¾ati relativno ureÄ‘enje
    - opÅ¡ta Å¡ema
        1. odaberi segmenti hromozoma prvog roditelja
        2. iskopiraj ovaj segment u prvo dete
        3. iskopirati preostale vrednosti (brojeve) tako da kopiranje poÄinje desno od kopiranog segmenta koriÅ¡Ä‡enjem redosleda datog u drugom roditelju
        4. identiÄno za drugo dete
    - ![](./imgs/ukrstanje_prvog_reda.png)
    
- delimiÄno ukrÅ¡tanje (RMH)
    - opÅ¡ta Å¡ema za roditelje P1 i P2:
    1. odaberi sluÄajan segment i kopiraj ga od P1
    2. poÄev od pozicije poÄetnog segmenta, traÅ¾i elemente u tom segmentu za P2 koji nisu bili kopirani
    3. za svaki od ovih $i$ pronaÄ‘i vrednost $j$ iz P1 koja je kopirana na njegovo mesto
    4. postavi $i$ na poziciju zauzetu sa $j$ u P2, poÅ¡to zasigurno znamo da j neÄ‡e biti tamo, jer je veÄ‡ u detetu
    5. ako je mesto na kojem se nalai j u P2 veÄ‡ zauzeto vrednoÅ¡Ä‡u k, onda postavi i na poziciju koju zauzima k u P2
    6. preostale elemente kopirat iz P2
    - drugo dete se kreira analogno
    - ![](./imgs/rmh.png)
    TODO

---
## `22.` Populacioni modeli i selekcija
- generacijski model (Generation getetic algorithm - GGA)
    - koristi ga SGA
    - svaka jedinka preÅ¾ivi taÄno jednu generaiju
    - ceo skup roditelja je zamenjen svojim potomcima
- model sa stabilnim stanjem - Steady-state GA (SSGA)
    - jedno dete se generiÅ¡e po generaciji
    - jedan Älan generacije biva zamenjen njime
- generacijski jaz
    - udeo populcije koja se menja
    - 1.0 za GGA, 1/_veliÄina populacije_ za SSGA

- selekcija se moÅ¾e javiti u dva navrata
    - selekcija roditelja za ukrÅ¡tanje
    - selekcija preÅ¾ivelih - biranje iz skupa roditelja + deca onih koji Ä‡e preÄ‡i u novu generaciju

- razlika meÄ‘u selekcijama se pravi na osnovu
    - operatora: definiÅ¡e razliÄite verovatnoÄ‡e
    - algoritmi: definiÅ¡u kako se verovatnoÄ‡e implementiraju

### Primer selekcije: SGA
- oÄekivani broj kopija jedinke i
    - $E(n_i) = \mu f(i)/<f>$
    - kvazi verovatnoÄ‡a bazirana na fitnes vrednostima
    - $f(i)/<f>$ - normalizovan fitnes
    - $\mu$ - veliÄna populacije
    - $f(i)$ - fitnes jedinke
    - $<f>$ - proseÄan fitnes opulacije

    - Ruletksa selekcija
        - za datu raspodelu verovatnoÄ‡a se okrene ruletski toÄak n puta
        - nema garantovane gornje ili donje granice $n_i$
    - Baker SUS algoritam
        - SUS - Stohastic universal sampling
        - n ekvidistantnih graniÄnika postavljeno na toÄku, jedno okretanje
        - garantuje da je $floor(E(n_i)) \le n_i \le ceil(E(n_i))$

- Fitnes-rsazmerna selekcija
    - problem je Å¡to jedna visoko kvalitetna jedinka moÅ¾e brzo da preuzme Äitavu populaciju ako su ostale jedinke znaÄajno loÅ¡ije, rana konvergencija
    - kada su fitnesi sliÄni (pred kraj) selekcioni pritisak je loÅ¡
        - selekcioni pritisak definiÅ¡e koliko su favorizovana dobra reÅ¡enja
        - kada su fitnesi relativno sliÄni (bliski) smanjuje se favorizacija
        - skaliranje moÅ¾e da popravi:  
            - skliranje prema najgorem: $f`(i)=f((i) - \beta ^t$, gde je $\beta$ najgori fitnes u poslednjoj generaciji

- rang-bazirana selekcija
    - pokuÅ¡ava da prevaziÄ‘e problem fitnes-srazmerne selekcije
    - vrednost fitnesa nema apsolutan veÄ‡ relativan znaÄaj ovde
    - najbolja jedinka ima najviÅ¡i rang $\mu$, a najgori rang 1
    - troÅ¡ak na sortiranje je obiÄno zanemarljiv

- turnirska selekcija
    - ovo moÅ¾e biti usko grlo paralelnim maÅ¡inama
    - oslanja se na pristustvo eksternih fitnes funkcija koje moÅ¾da ne postoje uvek, npr evolucija botova za igrice (ovde ne znamo fitnes ali moÅ¾emo da utvrdimo ko bolje igra)
    - odaberemo k Älanova na sluÄajan naÄin, potom se odabere najbolji od njih
    - ostale jedinke se biraju na isti naÄin
    - verovatnoÄ‡a odabira jedinke i zavisi od:
        - ranga i 
        - vrednosti k, veÄ‡e k je veÄ‡i selekcioni prtisak
        - da li se takmiÄari biraju sa vraÄ‡anjem, odabir sa vraÄ‡anjem pojaÄava selekcioni pritisak
    - za k=2, vreme potrebno da najbolja jedinka preuzme populaciju je ista kao kod linearnog rangiranja za s=2*p

- selekcija preÅ¾ivelih
    - metoda sliÄna onoj za odabira roditelja za ukrÅ¡tanje
    - u generacijskom modelu trivijalno, briÅ¡u se najstariji, tj svi roditelji
    - u opÅ¡tem sluÄaju se mogu birati/brisati bilo koje jedinke iz skupa roditelja i dece
    - dve grupe pristupa:
    1. selekcija zasnovana na starosti
        - kako kod SGA
        - SSGA moÅ¾e da implementira brisanje sluÄajne (Å¡to se ne preporuÄuje) ili brisanje najstarije

    2. fitnes-srazmerna selekcija
        - primena ruletske ili turnirske...
    - Elitizam je specijalni sluÄaj
        - Äesto se koisti i kod GGA i SSGA
        - uvek zadrÅ¾ava kopiju najboljeg reÅ¡enja do sad

---
## `23.` Teorema o shemama
- teorijska osnova iza genetskih algoritama i genetskog programiranja, John Holland 70ih godina
- nejednakost koja objaÅ¡njava evolutivnu dinamiku  

**Teorema:** kratke sheme sa natproseÄnim fitnesom postaju eksponencijalno uÄestalije tokom generacija

- shema je Å¡ablon koji identifikuje podskup niski koje su sliÄne na pojedinaÄnim pozicijama, kao regularni izrazi na nivou binarnih izraza

_Primer:_ za binarne niske duÅ¾ine 6, primer shheme je 1\*10\*1 gde svaka shema opisuje sve niske duÅ¾ine 6 sa fiksiranim bitovima na 4 opisane pozicije

- red sheme o(H) - broj fiksiranih pozicija
- $\delta (X)$ - udaljenost izmeÄ‘u prve i poslednje fiksirane pozicije
- fitnes sheme je proseÄan fitnes svih niski koje pripadaju shemi

**Teorema:** 
$$E(m(H, t+1)) \ge m(H, t)f(H)/a_t[1-p]$$
- $m(H,t)$ - broj niski koje pripadaju shemi H u generaciji t
    - broj jedinki koje se uklapaju u prethodnoj iteraciji utiÄe na broj jedinki koje Ä‡e se preneti u narednu generaciju
- $f(H)$ - proseÄan fitnes sheme H, 
    - Å¡to je veÄ‡i fitnes neke posmatrane sheme to je veÄ‡a Å¡ansa da se broj takvih jedinki poveÄ‡a 
- $a_t$ - proseÄan fitnes u generaciji t
- p - verovatnoÄ‡a da je ukrÅ¡tanje ili mutacija _razbiti_ shemu 
    - $p=\delta(H)/(l-1)p_c+o(H)p_m$
    - $l$ - duÅ¾ina genotipa
    - $p_c$ i $p_m$ - verovatnoÄ‡e ukrÅ¡tanja i mutacije


- oÄekivani broj jedinki koje imaju odreÄ‘enu shemu H u nekoj generaciji t+1 je veÄ‡i od broja jedinki koji se uklapaju u shemu H puta fitnes sheme kroz proseÄan fitnes svih jedinki u populaciji
- Å¡to je udaljenost prve i poslednje fiksirane pozicije veÄ‡a veÄ‡a je i Å¡ansa de Ä‡e se ukrÅ¡tanjem razbiti shema

---
## `24.` Genetsko programiranje - pregled koncepata i opÅ¡ta shema
- razvijeno u Americi 90ih godina, J. Koza
- primenjuje se u maÅ¡inskom uÄenju, predikcija, klasifikacija
- konkurentan neuonskim mreÅ¾ama i sliÄnim metodama, ali je sporo i zahteva ogromen populacije
- Specijalne karakteristike:
    - nelinearni hromozomi, stabla, grafovi
    - mutacija je moguÄ‡a ali ne neophodna, za razliku od GA

- TehniÄke karakteristike:

|  |  |
|---|---|
| reprezentacija | stablo|
| ukrÅ¡tanje | razmena stabala, nema smisla viÅ¡epozicioni|
| mutacija | sluÄajna promena u stablu,sluÄajno odabrano podstablo zamenimo sluÄajno generisanim|
| selekcija roditelja | fitnes srazmerna |
| selekcija preÅ¾ivelih | generacijska zamena |
|

_Primer:_ Banka odluÄuje da li Ä‡e nekome dati kredit. Na osnovu istorijski podataka pravimo stablo odluÄivanja. Npr gledamo broj dece, platu i braÄni status.
- kada generiÅ¡emo stablo odluÄivanje ide brzo
- taÄke prostora su kandidat stabla, veliki prostor moguÄ‡ih reÅ¡enja
```
IF formula THEN dobar ELSE loÅ¡
```
- moguÄ‡i model:
```
IF broj_dece=2 AND plata>80000 THEN dobar loÅ¡
```
- prostor pretrage (fenotip) je skup svih formula
- fitnes formule - procenat dobro klasifikovanih primera
- prirodna reprezentacija formule (genotip) je stablo
- imamo tehniku koja ne zapada u lokalne optimume, globalnija je
- genetski algoritam kreÄ‡e od sluÄajno generisane populacije stabala, izgeneriÅ¡e se da prati ograniÄenja operatora
- formiraju se dopustiva reÅ¡enja

### Reprezentacija stabla
- Stablima se moÅ¾e predstavljati veliki broj formula
* AritmetiÄka formula
    - ![](./imgs/aritmeticko_stablo.png)
* LogiÄka formula
    - ![](./imgs/logicko_stablo.png)
* Program
    - ![](./imgs/program.png)


- u genetskih algoritmima, evolutivnim strategijma, evolutivnom programiranju hromozomi su linearne strukture - nizovi bitova, celih brojeva, relanih brojeva, permutacije... veliÄina hromozoma je fiksna
- stablo-hromozomi su nelinearne strukturei  stablo moÅ¾e biti proizvoljne dubine i Å¡irine

### Reprezentacija stabla
- simboliÄki izrazi mogu biti definisani pomoÄ‡u
    - skupa termova T
    - skupa funkcija F sa pridruÅ¾enim arnostima
- dalje se moÅ¾e koristiti sledeÄ‡a rekurzivna definicija
1. Svaki $t \in T$ je korektan izraz
2. $f(e_1, ... ,e_n)$ je korektan izraz ako $f \in F$, $arity(f)=n$ i $e_1, ... ,e_n$ su korektni izrazi
3. ne postoje druge korektne forme izraza
- u opÅ¡tem sluÄaju izrazi u GP nisu tipizirani, tj svaki $f \in F$ moÅ¾e uzeti bilo koji $g \in F$ kao argument

### Generisanje potomaka
- genetsko prograiranje koristi **ILI** ukrÅ¡tanje **ILI** mutaciju, ali ne oba
- za razliku od genetski algoritama koji koriste i ukrÅ¡tanje i mutaciju
- ![](./imgs/ga_vs_gp.png)

### Selekcija
- selekcija roditelja je obiÄno fitnes-srazmerna
- selekcija u veoma velikim populacijama
    - populacija se rangira prema fitnesu i podeli u dve grupe
    - grupa 1 - najbolji x% populacije
    - grupa 2 - ostalih (100-x)%
    - 80% operacije selekcije se vrÅ¡i nad grupom 1, a presotalih 20% nad grupom 2
    - procenti su odreÄ‘eni empirijski i zavise od veliÄine populacije, za populacije 1000, 2000, 4000, 8000, x = 32%, 16%, 8%, 4%
- selekcija preÅ¾ivelih
    - standardni pristup je generacijski
    - model sa stabilnim stanjem i elitizmom postaje popularan u poslednje vreme
- zbog veÄ‡i moguÄ‡nosti je ovde potrebna veÄ‡a kontrola, malo veÄ‡a doza elitima, manja doza nasumiÄnosti, da bi se oÄuvao neki kvalitet

### Inicijalizacija populacije
- postavi se maksimalna dubina stabla $D_{max}$
- Balansirani pristup
    - teÅ¾i se ka balansiranom stablu dubine $D_{max}$
    - Ävorovi na dubini $d<D_{max}$ se sluÄajno biraju iz skupa fnkcija F
    - Ävorovi na dubini $d=D_{max}$ se sluÄajno biraju iz skupa termova T

- OgraniÄeni pristup
    - teÅ¾i se ka stablu ograniÄene dubine $\le D_{max}$
    - Ävorovi na dubini $d<D_{max}$ se sluÄajno biraju iz skupa fnkcija $F \cup T$
    - Ävorovi na dubini $d=D_{max}$ se sluÄajno biraju iz skupa termova T

- standardna GP inicijalizacija: kombinovan pristup koji koristi i balansirani i ograniÄeni pristup, svaki po pola populacije

### Pristup zasnovan na poveÄ‡anju
- Bloat - tendencija ka udebljanju, stbla unutar populacije vremenom rastu
- debata u nauÄnim istraÅ¾ivanjima
- **Okamova britva**: ako imamo dva algoritma sa identiÄnim performansama bolje korsititi jednostavniji
- potrebne su kontramere poput spreÄavanja upotrebe operatora koji prave preveliku decu i penalizacija prevelikih jedinki

_Primer:_
- ![](./imgs/ga_regresija.png)
- jednostavna interpretacija, Äitljivo
- potencijalno beskonaÄna petlja

---
## `25.` Operator mutacije i ukrÅ¡tanja kod genetskog programiranja.

### Mutacija
- najÄeÅ¡Ä‡e: zameni sluÄajno odabrani podstablo novim sluÄajno generisanim stablom
- ![](./imgs/ga_mutacija.png)
- mutacija ima dva parametra
    - $p_m$ - verovatnoÄ‡a odabira mutacije, u suprotnom je selekcija, savet je da bude blisko nuli, npr 0.05
    - verovatnoÄ‡a odabira unutraÅ¡nje taÄke, tj korena podstabla za zamenu
- veliÄina deteta moÅ¾e da bude veÄ‡a od veliÄine roditelja
- ako se ovo deÅ¡ava kroz generacije stabla postaju sve veeÄ‡a i kompleksnija
- postoje tehnike koje spreÄavaju rast potomaka

### UkrÅ¡tanje
- najÄeÅ¡Ä‡e: zameni dva sluÄajno odabrana podstabla izmeÄ‘u roditelja
- ukrÅ¡tanje ima sva parametra
    - $p_c$ - verovatnoÄ‡a odabira ukrÅ¡tanja, u suprotnom je mutacija
    - verovatnoÄ‡a odabira unutraÅ¡nje taÄke, tj pozicije za ukrÅ¡tanje kod oba roditelja
- veliÄina deteta moÅ¾e da bude veÄ‡a od veliÄine roditelja
- ![](./imgs/ga_ukrstanje.png)


---
## `26.` Intelignecija rojeva - uopÅ¡teno.
- PÄele
    - kooperacija u okviru kolonije
    - mahanjem krilima reguliÅ¡u temperauru unutar koÅ¡nice
    - efikasnost se postiÅ¾e specijalizacijom - podelom posla u okviru kolonije
    - komunikacija - izvor hrane se koristi u skladu sa njihovom blizinom saÄ‡u i kvalitetom

- Ose
    - tragaÄi za hranom, tragaÄi za vodom, roditelji
    - sloÅ¾ena gnezda - horizontalne kolone, zaÅ¡titne opne, centralni ulazni hol
    - nema centralizovanog sistema, nekako indirektno komuniciraju

- Termiti
    - konusni spoljni zidovi i ventilacioni otvori
    - legla u centralnoj koÅ¡nici
    - spiralni ventilacioni otvori za hlaÄ‘enje
    - potporni stubovi

- Mravi
    - prave puteve do mesta sa hranom tako Å¡to ostavljaju tragove feromona
    - formiraju lanc svojim telima u cilju pravljenja mosta preko liÅ¡Ä‡a i granja
    - podela posla izmeÄ‘u viÅ¡e i manje bitnih mrava, dobra specijalizacija posla
    - mogu optimizovati putanju da manje troÅ¡e energiju

- Karakteristike socijalnih insekata  

|  |  |
|---|---|
| fleksibilnost | kolonija savladava unutraÅ¡nje preturbacije kao i spoljaÅ¡ne izazove, kombinacija sluÄajnosti i onoga Å¡to se veÄ‡ radi, primenjuju diversifikaciju i intensifikaciju |
| robusnost | zadaci se zavrÅ¡avaju i ako neke jedinke zakaÅ¾u| 
| decentralizovanost | ne postoji centralni mehanizam kontrole niti koncept lidera |
| samoorganizovanost | putevi do reÅ¡enja vremenom iskrsnu, nisu unapred predefinisani |
|

- jednostavne jedinke mogu da grade globalno kompleksno ponaÅ¡anje

### ikosistem simulacija
- svaki agent X ima dodeljena dva nasumiÄna protivnika A i B
- ![](./imgs/ikosistem1.png)
- pravilo za X je da se postavi tako da bude na putu izmeÄ‘u A i X
- ![](./imgs/ikosistem2.png)
- mala promena pravila drastiÄno utiÄe na kolektivno ponaÅ¡anje

- ![](./imgs/mravi.png)
- kada se pojavi prepreka mravi Ä‡e se ponaÅ¡ati haotiÄno,dok ne naÄ‘u put oko prepreke, kada se na putu poveÄ‡a trag feromona skoro svi mravi Ä‡e pratiti taj put

### Problemi sa inteligentnim rojevima
- teÅ¡ko se programira jer je teÅ¡ko kodirati i dekodirati
- reÅ¡enja iskrsnu unutar sisitema
- reÅ¡enja su rezultat ponaÅ¡anja i interakcije izmeÄ‘u pojedinaÄnih agenata (jedinki) u sistemu

### Glavni sastojci samoorganizacije
- pozitivna povratna sprega - positive feedback
    - nagrada pozitivnog ponaÅ¡anja
- negativna povratna sprega - negative feedback
    - kazna negativnog ponaÅ¡anja
- pojaÄavanje i smanjivanje sluÄajnosti
- oslanjanje na meÄ‘usobne interakcije agenata

### Svojstva samoorganizacije
- kreiranje struktura - gnezda, tragovi, socijalno ureÄ‘enje- hijerarhija
- promene su rezulat postojanja viÅ¡estrukih puteva razvoja - nekoordinisane i koordinisane faze
- postojanje viÅ¡e stabilnih stanja - npr dva jednako dobra izvora hrane

### Tipovi interakcije socijalnih insekata
- direktna interakcija
    - razmena teÄnosti i hrane, vizuelni kontak, hemijski kontakt - feromoni
- indirektna interakcija - stigmergija - stigmergy
    - individualno ponaÅ¡anje menja okruÅ¾enje koje posle izaziva promenu ponaÅ¡anja drugih individua
    - kod mrava stigmergija eliminiÅ¡e potrebu za direktnom meÄ‘usobnom komunikacijom
    - efekat je da mrav sprovode koordinisane aktivnosti bez obraÄ‡anja jedan drugom kao Å¡to to rade ljudi

- neke popularne primene
    - optimizacija ruta
    - klasterovanje i sortiranje
    - podela posla
    - kooperativni transport
    - igradnja sloÅ¾enih struktura - gnezda

### Optimizacija ruta mravima - TSP
- $d_{ij}$ - udaljenost izmeÄ‘u gradova i j
- $\tau _{ij}$ - koliÄina feromona na luku (i,j)
- m agenata (mrava) 
- u svakom koraku, veroatnoÄ‡a odlaska od grada i do grda j je srazmerna $(\tau_{ij})^a (d_{ij})^{-b}$
    - verovatnoÄ‡a odlaska do nekog grada je srazmerna koliÄini feromona a obrnuto srazmerna udaljenosti
- feromoni isparavaju po fomruli $\tau (1 - \rho) \tau$
- kreÄ‡emo od nasumiÄne taÄke, graf je hamiltonov ciklus pa je svejedno odakle kreÄ‡emo
- ![](./imgs/tsp_mravi.png)

### Rutiranje u komunikacionim mreÅ¾ama
- agenti zapoÄinju put od polaznog ka ciljnom Ävoru
- svaki agent aÅ¾urira svoju tabelu rutiranja i komunicira sa ostalima
- ideja: ako ideÅ¡ ka ciljnom Ävoru u kom sam ja veÄ‡ bio ranije, daÄ‡u ti savet kuda da ideÅ¡
- uticaj agenta (validnost saveta) sa smanjuje sa starenjem
- agenti se veÅ¡taÄki usporavaju na zaguÅ¡enim Ävorovima (granama) - simulacija realnosti
- sporije ispravanje feromona > intensifikacija reÅ¡enja, saveti ostaju isit i vodi se sliÄnim reÅ¡enjima

### Klasterovanje
- ![](./imgs/klaster_mravi.png)
- mravi se kreÄ‡u ka hrani, a ona je centroid klastera
- izolovana hrana ima veÄ‡u Å¡ansu da bude pokupljena od strane agenta koji nosi tovar
- verovatnoÄ‡a uzimanja tovara: $p_p = [k_1 / (k_1 + f)]^2$
- $f$ - gustina hrane u datoj okolini
- agent koji nosi tovar ima veÄ‡u Å¡ansu da ispusti tovar ukoliko u blizini postoji drugi tovar: $p_d = [f / (k_2 + f)]^2$
- operatori se moraju direktno prilagoditi problemu

### Podela posla
- _Messor barbarous_ - mravi u jugoistoÄnoj Å paniji, donose hranu od izvora ka gnezdu u brigadama od Å¡estoro radnika
- prvo manji mravi izviÄ‘aÄi uzimaju hranu sa izvora i nose je duÅ¾ puta dok ne sretnu veÄ‡e radnike, prelaze manji put i troÅ¡e manje energije
- veÄ‡i radnici preuzimaju hranu i nose je dalje dok se manji vraÄ‡aju nazad do izvora
- ![](./imgs/spanski_mravi.png)
- sliÄno organizaciji amerÄkog tacko bella

### Kooperativni transport
- kada sam mrav ne moÅ¾e da nosi veliki komad hrane viÅ¡e mrava se aktivira
- u poÄetku se mravi kreÄ‡u nesinhronizovano, bez nekog napretka
- nakon nekog vremena uspevaju da pomere plen, i onda nastavljaju da rade sliÄnu aktivnost koja daje rezultate

### Kolektivna robotika
- reprodukcija kolektivne koordinacije sa grupom veoma jednostavnih robota
- roboti su zajedno gurali kutiju
- moÅ¾da ne najefikasniji naÄin, ali je potencijalno fleksibilan i pogodan za prilagoÄ‘avanje pod najrazliÄitijim okolnostima
- potrebno je adekvatno definisati pravila
- npr imamo algoritam ponaÅ¡anja i roboti se prilagoÄ‘avaju Å¾ivotu na drugoj planeti

### Izgradnja sloÅ¾enih struktura
- agenti se pomeraju nasumiÄno unutar 3D mreÅ¾e
- agent postavlja Ä‡eliju/ciglicu svaki put kad pronaÄ‘e stimulativnu konfiguraciju
- postoji tabela pravila za stimulativne konfiguacije
- pozicija je stimulativna npr ako ima ciglicu pored ili ispod
- prostor moguÄ‡nosti stimulativnih izvdenih konfiguracija je ogroman
- ![](./imgs/slozene_strukture.png)

### Opasnost pravila
- mravi atnici napravili krug smrti
- krug preÄnika 400 metara i svakom mravu je trebalo oko 2 i po sata da ga obiÄ‘e
- veliki broj mrava uginuo jer nisu mogli da izaÄ‘u iz kruga, nekoliko je uspelo da se izvuÄe

---
## `27.` Optimizacija rojevima Äestica - opÅ¡ti koncepti i osnovni algoritam
- PSO - Particle Swarm Optimization
- koren u socijalnoj psihologiji
- rojevi Äestica su na neki naÄin sliÄni celularnim automatima - CA:
    - svaka Ä‡elija aÅ¾urira svoje stanje paralelno sa ostalim
    - svaka nova vrednost neke Ä‡elije zavisi od starih vrednosti i od vrednosti svojih suseda
    - sve Ä‡elije se aÅ¾uriraju primenom istog pravila
- Ä‡elije se menjaju iterativno
- PSO nije nastao pre CA, nego se posle ispostavilo da liÄe
- Äestice unutar roja se mogu poistovetiti sa Ä‡elijama unutar CA, samo se njihova stanja menjaju u mnogo dimenzija istovrermeno

- James Kennedy i Russell Eberhart: _ÄŒestice unutar roja imitiraju socijalno ponaÅ¡anje ljudi ili insekata. ÄŒestice (jedinke) interaguju meÄ‘usobno dok uÄe i sopstvenog iskustva, Å¡to postepeno pomera populaciju u pravcu boljih regiona reÅ¡enja problema._
- Äestice a ne taÄke jer brzina i ubrzanje viÅ¡e priliÄe Äesticama nego taÄkama

- imamo kognitivnu komponentu - znamo Å¡ta smo radili, gde se nalazimo, delimiÄno vidimo Å¡ta drugi rade

- zahtevna metoda, uopÅ¡tenija od mravljih kolonija, lakÅ¡e se prilagoÄ‘ava posmatranom problemu

- za probleme u realnom, diskretnom ili meÅ¡ovitom prostoru pretrage
- za probleme sa viÅ¡estrukim lokalnim optimumima, ograniÄenjima
- za probleme viÅ¡eciljne, dinamiÄke optimizacije

### Originalni PSO
![](./imgs/originalni_pso.png)
- ako je Äestica imala veliku brznu mala je Å¡ansa da Ä‡e naglo da se smanji

### Pseudokod
- za svaku jedinku u populaciji se aÅ¾urira njena trenutna pozicija po potrebi

```
reandom_initial_population();
repeat 
    for i = population_size do
        if f(xi) < f(pi) then pi = xi;
        pg = min(p_neighbours)
        for d = 1 to dimmension do
            velocity_update();
            position_update();
        end;
    end;
until termination_criterion_met()
```

---
## `28.` Geometrijska interpretacija optimizacije rojevima Äestica i primeri.

### Inercijalna teÅ¾ina
![](./imgs/inercijalna.png)
- w predstavlja inerciju
- njom kontroliÅ¡emo eksploraciju i eksploataciju
    - $w \ge 1$ - brzina raste tokom vremena, pa roj divergira
    - $0 < w < 1$ - Äestica usporava pa konvergencija zavisi od vrednsoti $c_1$ i $c_2$
    - $w < 0$ - brzina se smanjuje tokom vremena, na kraju se smanji na 0 i time se zaustavlja algoritam
- manja brzina > manje istraÅ¾uje prostor > manje diversifikacija
- ako se brzina poveÄ‡a Äestice divergiraju, tj sve viÅ¡e se udaljavaju jedna od druge
- empirijski je pokazano da dobre rezulatet daju vrednosti
    - $w=0.7298$
    - $c_1 = c_2 = 4.9618$
- Eberhart i Shi savetuju smanjenje inercije tokom vremena, obiÄno u rasponu 0.9 i 0.4, ovim se postepeno prebacuje reÅ¾ima veÄ‡e eksploracije u reÅ¾im veÄ‡e eksploatacije

![](./imgs/vizuelizacija_pso.png)

### Primer
![](./imgs/pso_primer.png)
- $x(k+1) = x_k + v(k+1) = (4,2) + (2.2, 2.8) = (6.2, 4.8)$


![](./imgs/primer_pso.png)

### Ako imamo jednu Äesticu
- nema nasumiÄnosti, tj stohastiÄke komponente
- postoji jedna dimenzija
- unapred odreÄ‘ene poÄenta pozicija i brzina
    - $v \leftarrow wv + c_1(p_i-x) + c_2(p_g-x$)
    - $x \leftarrow x + v$
- ako je $w=0.7,\ c_1=c_2=0.7$, znamo poÄetne pozicije i brzinu
- posmatramo $f(x)=x^2$ na $[-20, 20]$
- imamo dva sluÄaja
1. Prve dve pozicije su sa iste strane minimuma, npr x=-20 i v=3.2
    - poÅ¡to je liÄni najbolji uvek jednak x Äestica nikad neÄ‡e moÄ‡i da dostigne minimum, prerana konvergencija
    - nema neke tendencije da cik cak potezima doÄ‘e do globalnog optimuma bez stohastiÄk komponente
2. Pre dve pozicije okruÅ¾uju minimum, npr x=-2, v=6.4
    - Äestie osciluju oko minimuma poÅ¡to liÄni najbolji nije uvek x, dobija se bolje ponaÅ¡anje
![](./imgs/cestica.png)


### Putanja dve Äestice
- interakcije dve Äestice se modeluje grafom uticaja
    - dva istraÅ¾ivaÄa i dve memorije
    - svaki istraÅ¾ivaÄ prima infomracije od dve memorije ali informiÅ¡e samo jednu memoriju  
![](./imgs/graf_uticaja.png)

- dve Äestice su dva istraÅ¾ivaÄa i dve memorije
- imamo dva sluÄaja kao u prethodnom, ali ovde Äestice rade zajedno

![](./imgs/dve_cestice.png)

- memorija Äestice 2 je uvek bolja od memorije 1, pa se Äestica 2 ponaÅ¡a isto kao i kada je bila sama
- ali Äestica 2 sada ima koristi od memorije Äestice 2 Å¡to na kraju izaziva konvergenciju (levo)

- opÅ¡tji sluÄaj: svaÄa Äestica je pod uticajem tuÄ‘e memorije samo povremeno
- konvergencija ka globalnom optimumu je tada verovatnija, ali ceo proces moÅ¾e biti sporiji
![](./imgs/dve_cestice2.png)


### Potencijalno opasno svojstvo
- ako je liÄna najbolja pozicija jednaka globalno najboljoj i kada je to jednako trenutnoj poziciji: $x_i = p_i = p_g$
- tada aÅ¾uriranje brzine zavisi samo od $w*v_i$, tj promena brzine je 0 pa pomeraj zavisi samo od inercije
- ako se ovo ponovi u viÅ¡e iteracija $w*v_i \rightarrow 0$, tj brzina se smanjuje na 0
- reÅ¡enje: omoguÄ‡iti da globalno najbolja Äestica vrÅ¡i lokalnu pretragu i koristi mutacije da prekine ovo stanje

### Ogoljeni PSO
- ako izbacimo brzinu
- ako su $p_i$ i $p_g$ konstantne, kanonski PSO pretraÅ¾uje prostor pretrage praÄ‡enjem normalne distribucije sa centrom izmeÄ‘u $p_i$ i $p_g$

### Binarni PSO
- pozicija se aÅ¾urira prema formuli: $x_{ij}(t+1) = 1\ za\ U(0,1)<sig(v_{ij}(t+1))$, inaÄe $x_{ij}(t+1) = 0$
- gde je $sig(v)=1/(1+e^{-v})$

---
## `29.` Varijante gbest i lbest algoritma i topologije uticaja.
### Topologija uticaja
![](./imgs/topologija_uticaja.png)
- prva je kompletna topologija, tj jedinka se ugleda na sve
- druga je topologija kada se gledaju samo dva suseda
- treÄ‡a je kada se sve jedinke ugledaju na jednu
- ne koristimo globlano najbolji za socijalnu komponentu, veÄ‡ imamo unapred zadatu topoplogiju uticaja zadatu na poÄetku, ugledamo se na unapred zadatke susede, ili na neki broj dinamiÄki odreÄ‘enih suseda
- Dva najÄeÅ¡Ä‡a modela:
    - gbest - svaka Äestica je pod uticajem najbolje jedinke iz Äitavog roja
    - lbest - svaka Äestica je pod uticajem najboljih jedinki iz neke svoje lokalne okoline

- ![](./imgs/topologija7.png)
    - graf uticaja nad rojem od 7 Äestica
    - svaka Äestica zavisi od same sebe i od svoja dva suseda

- ![](./imgs/topologija3.png)

- treba praviti kompromis izmeÄ‘u eksploatacije i eksploracije
- gbest najbrÅ¾e Å¡iri informacije Å¡irom populacije, loÅ¡e ako se prebrzo sazna neÅ¡to pa se ispostavi da ipak nije dobro
- lbest model koji koristi topologiju prstena najsporije, dobro za sloÅ¾en prostor pretrage
- za sloÅ¾ene viÅ¡emodalne funkcije bra populacija nije poÅ¾eljna
- ali sporije Å¡irenje informacija usporava konvergenciju

- Mendes i Kennedy - von Nojmanova topologija daje najbolje ponaÅ¡anje meÄ‘u mnogo razliÄitih topologija
    - severna, juÅ¾na, istoÄna i zapadna Äestica u dvodimenonalnoj reÅ¡etci

- ![](./imgs/topologija5.png)
- kao kod karnoovih mapa, susedi prvi i poslednji red

---
## `30.` Funkcija aktivacije
- ![](./imgs/fja_aktivacije.png)
a) linearna funkcija - samo prosledi vrednost  
b) step funkcija - ispod neke vrednosti argumenta je jedna vednost, a iznad druga  
c) rampa  
d) Sigmoidna gunkcija - daje vrednost izmeÄ‘u 0 i 1  
e) hiperboliÄki tangens - daje vrednost izmeÄ‘u -1 i 1  
f) Gausova funkcija, kao raspodela  
g) relu = max(0,x)

TODO

---
## `31.` Linearna i nelinearna razdvojenost.
### Linearna razdvojivost
- postavlja hiperravan koja razdvaja ulazne podatke na one sa izlazom ispod i iznad nekog praga
- ![](./imgs/lin_disj.png)
    - hiperravan koja odgovara funkciji logiÄke disjunkcije
    - kvartatiÄ‡i su 1 a kruÅ¾iÄ‡i 0
    - Å¾elimo da povuÄemo liniju (hiperravan) tako da su kruÅ¾iÄ‡i sa jedne strane a kvadatiÄ‡i sa druge
- Å¾elimo da aproksimiramo funkciju, tj nauÄimo da razlikujemo
- dovoljno da razdvojimo na da i ne, a perceptron moÅ¾e ovo da nauÄi
- ova funkcija je linearno separabilna, tj postoji hiperravan koja razdvaja na da i ne

### Nelinearna razdvojivost
- ako nije linearno razdvojivo, tj prostori sa da i ne se ne mogu razdvojiti jednom hiperravni
- ovo ne moÅ¾e da reÅ¡i jedan veÅ¡taÄki neurno, veÄ‡ je potreban sloÅ¾eniji model
- ![](./imgs/xor_nelin.png)
    - ne moÅ¾emo jednom linijom razdvojiti kruÅ¾iÄ‡e i kvadratiÄ‡e
    - ekskluzivna dijskunkcija je nelinearno razdvojiva
    - zahteva postojanje srediÅ¡njeg sloja sa dva neurona

---
## `32.` UÄenje veÅ¡taÄkog neurona.
- uÄenje gradijentnim spustom
- induktivni proces uÄenja
- dajemo primere sa odgovorima i nadamo se da Ä‡e funkcija uhvatiti suÅ¡tinu i da Ä‡e znati da reÅ¡i buduÄ‡e sluÄajeve
- veÅ¡taÄki neuron aproksimira funkciju opisanu ulazno izlaznim signalima podeÅ¡avanjem teÅ¾ina $v$ i parametra $\theta$
- skalarni parametar $\theta$ se moÅ¾e pridruÅ¾iti vektoru $v$ radi lepÅ¡e notacije
- teÅ¾ine se menjaju u skladu sa greÅ¡kom na izlazu
- ukuonu greÅ¡ku treba minimizovati:
$$\epsilon = \sum_{p=1}^{P_T} (t_p-o_p)^2 $$
- $t_p$ - ciljna vrednost
- $o_p$ - aproksimirana vrednost
- $P_T$ - broj podatak sprovedenih na ulaz
- kvadriranje u funkciji greÅ¡ke onemoguÄ‡ava da se greÅ¡ke skrate
- ![](./imgs/ucenje_neurona.png)
- naredna teÅ¾ina je zbir prethodne i promene teÅ¾ine
- promena teÅ¾ine je proporcionalna brzini uÄenja i negativnom gradijentu posmatrane teÅ¾ine, tako se tazuem izvod ??
- ako je velika brzina uÄenje onda prebrzim oscilovanjem moÅ¾emo preskoÄiti reÅ¡enje
- informacije o greÅ¡ci se koriste tako da se teÅ¾ine menjaju u skladu sa negativnim gradijentom
- ako je veÄ‡a greÅ¡ka pravimo jaÄe promene u negativnom smeru od teÅ¾inama tih neurona
- korekcija teÅ¾ine zavisi od magnitude, koliko je svaki teÅ¾inski faktor uticao na nastanak greÅ¡ke

- ![](./imgs/primer_ucenje.png)

---
## `33.` Tipovi organizacija veÅ¡taÄkih neuronskih mreÅ¾a, slika sa objaÅ¡anjenjem.
### UÄenje ueuronskih mreÅ¾a
- pojedinaÄan neuron moÅ¾e da nauÄi samo linearno razdvojivu funkciju
- grupisanje neurona u mreÅ¾u omoguÄ‡ava uÄenje nelinearno razvojivih funkcija
- uÄenje mreÅ¾a je kompleksnije i raÄunarsk zahtvnije
- nadgledano uÄenje - zahteva skup podataka za trening, svaki podatak ima pridruÅ¾enu ciljnu promenljivu
- nenadgledano uÄenje

### MreÅ¾ensa propagacijom unapred
- FNN - Feedfoward neural network
- najmanje tri sloja: 
    - ulazni - tu dolaze iformacije iz spoljnog sveta
    - srednji
    - izlazni
- izlaz se raÄuna jednim prolaskom kroz mreÅ¾u
- neuroni jednog sloja su povezani sa svim neuronima narednog sloja
- ![](./imgs/ffnn.png)
- ![](./imgs/ffnnf.png)

### Rekurentne neuronske mreÅ¾e
- Elman SRNN - Simple recurrent neural network
- kopija skrivenog slja se vraÄ‡a na ulaz (kontekstni sloj)
- cilj je upotreba prethodnog stanja mreÅ¾e
- omoguÄ‡ava uÄenje temporalnih zavisnsoti
- informacija ne ide samo unapred veÄ‡ postoji povratna sprega izmeÄ‘u izlaza i ulaza, izlaz se vraÄ‡a ponovo na ulaz
- imaju dve verzije, jedna vraÄ‡a samo sa poslednjeg sloja, a druga moÅ¾e i sa ostalih slojeva

- ![](./imgs/srnn.png)
- ![](./imgs/srnnf.png)

- Jordan SRNN - kopija izlaznog sloja se sproodi na ulaz, tzv sloj stanja
- ![](./imgs/jsrnn.png)

### Kaskadne neuronske mreÅ¾e
- CNN - Casade neural network
- svi ulazi su spojeni sa svim skrivenim i svim izlaznim elementima
- elementi srednjeg sloja su spojeni sa svim izlaznim i svim narednim elementima srednjeg sloja
- ![](./imgs/cnn.png)
    - postoje preÄice i duÅ¾i putevi u mreÅ¾i
    - efektivno se odrÅ¾ava viÅ¡e teÅ¾ina
    - ide u jednom smeru, od neurona viÅ¡eg sloja se Å¡alje ka neuronima niÅ¾eg sloja

---
## `34.` Pravila nadgledanog i nenadgledanog uÄenja.

### Pravila nadgledanog uÄenja
- dat je konaÄan skup ureÄ‘enih parova ulznih vrednosti i pridruÅ¾enih ciljnih vrednosti:  
$D = \{ dp=(z_p, t_p) | p = 1,...,P \}$
- $z_{i,p}, t_{k,p} \in R\ za \ i=1,...,l\ i \ k=1,...,K$
- $l$ - broj ulaznih signala
- $K$ - broj izlaznih signala
- $P$ - broj trening podataka
- tada moÅ¾emo predstaviti sledeÄ‡u zavisnost: $t_p= \mu (z_p) + \eta p$
- $\mu (*)$ - nepoznata ciljna funkcija
- $\eta p$ - Å¡um
- uÄimo induktivno iz primera, a Å¾elimo da predviÄ‘amo vrednosti za nove podatke
- nije kao kod interpolacije gde treba da se uklopi u skup taÄaka
- npr predviÄ‘amo vlaÅ¾nost vazuha na osnovu istorijskih podataka

- cilj je aproksimirati $\mu (*)$ na osnovu podataka iz D
- polazni skup se obiÄno deli na 3 dijsunktna skupa:
    - $D_T$ - trening skup za aproksimaciju
    - $D_V$ - skup za validaciju (memorizacija), moÅ¾e da smanji preprilagoÄ‘avanje, ali nije obavezan
    - $D_G$ - skup za testiranje (procena kvaliteta, ne glda se pri uÄenju uopÅ¡tavanja)
- tokom faze uÄenja se minimizuje empirisjka greÅ¡ka podeÅ¡avanjem W
- ![](./imgs/nagledanof.png)
- metode lokalne optimizacije, npr gradijentni spust
- metode globalne optimizacije, npr metaheuristike
- preprilagoÄ‘avanje - jako doro radi na treningu, a loÅ¡e na testu
- potprilagoÄ‘avanje - nije dovoljno dobro obuÄen model

### Gradijenti spust za uÄenje NN
- Sastojis se iz dve faze
1. propagacija signala unapred, jednostavno raÄunanje signala za FFNN
2. propagacija greÅ¡ke unazad, signal greÅ¡ke se Å¡alje unazada ka ulaznom sloju pri Äemu se vrÅ¡i izmena teÅ¾inskih koeficijenata
- imamo viÅ¡e greÅ¡aka koje treba rasporediti po mreÅ¾i, a ne okriviti jedan sloj za svu geÅ¡ku
- funkcija cilja minimizacije moÅ¾e biti sum kvadratna greÅ¡ka 
    - SSE - Sum squared error
    - $1/2 \sum_{k=1}^K(t_k-o_k)^2$
    - 1/2 da bi se skratilo pri izvodu
- kao funkcija aktivacije na izlaznom i srediÅ¡njem sloju moÅ¾e da se koristi sigmoidna funkcija
    - $o_k = f_{ok} (net_{ok} = 1 / (1 + e^{-net_{ok}}))$

### StohastiÄki gradijentni spust za uÄenje NN
- ![](./imgs/stohasttickenn.png)
- ![](./imgs/stohastickenn2.png)

- ![](./imgs/stohastickinnalg.png)
    - varira se redosled ulaza podataka u mreÅ¾u
    - nema preferrencije za teÅ¾ine
    - podatci se propagiraju kroz mreÅ¾u dok se ne zadovolji neki uslov

### Nendgledano uÄenje
- ne daje se oÄekivani izlaz
- algoritam mora sam da utvrdi postojanje pravilnosti u ulaznim podacima
- veÅ¡taÄke neuonske mreÅ¾e omoguÄ‡avaju pravljenje asocijacija izmeÄ‘u Å¡ablona (Pattern association)
- joÅ¡ se nazivaju asocijativna memorija ili asocijativne neuronske mreÅ¾e
- npr. seÄ‡enje na sliku moÅ¾e da izazove oseÄ‡anja kod Äoveka

---
## `35.` Asocijativna neuronska mreÅ¾a i Hebovo uÄenje
### Asocijativne neuoronske mreÅ¾e
- obiÄno dvoslojne
- cilj je omoguÄ‡iti ostvarivanje asocijacija
- razvoj ovakvih mreÅ¾a je zasnovan na studijama vizuelnog i zvuÄnog korteksa kod mozga sisara
- topoloÅ¡ka organizacija neurona omoguÄ‡ava asocijaciju
- dodatna poÅ¾eljna karakteristika je zadrÅ¾avanje starih informacija, a ovo obiÄno ne moÅ¾e nadgledanim uÄenjem
- stvaramo asocijaciju izmeÄ‘u sliÄnih podataka, npr sve objekte sliÄne nijanse

### Primer asocijativne mreÅ¾e
- Hebova mreÅ¾a / Hebovo uÄenje
- funkcija koju uÄi ovakva mreÅ¾a je preslikavanje ulaznog Å¡ablona u izlazni
- $f_{NN}:R^I \rightarrow R^K$
- viÅ¡edimenzioni ulaz ($z_i$) i izlaz ($o_i$) su povezani, pa gledamo preslikavanje iz ulaza na izlaz
- ![](./imgs/asocmreza.png)

### Hebovo uÄenje
- neuropsiholog Heb
- teÅ¾ina se aÅ¾urira na osnovu korelacije izmeÄ‘u aktivacionih vrednosti neurona
- zasnovano na hipotezi: _potencijal neurona da ispali signal je zavistan od potencijala okolnih neurona._
- uÄi na osnovu korelacije ulaznog i izlaznog signala
- teÅ¾ina izmeÄ‘u dva korelisana neurona se pojaÄava
    - gledamo k-ti ulazni i i-ti izlani neuron
    - $u_{ki}(t) = u_{ki}(t-1) + \Delta u_{ki}(t)$
    - $\Delta u_{ki}(t) = \eta o_{k,p} z_{i,p}$
    - $\Delta$ - stepen brzine uÄenja
    - $o_{k,p}$ - vrednost izlaza
    - $z_{i,p}$ - vrednsot ulaza
- gledamo teÅ¾inu i-tog i j-tog singla, Å¡ta je uÅ¡lo u i, a Å¡ta je izaÅ¡lo na k
- ako su pozitivno korelisani teÅ¾ina se poveÄ‡ava vremenom, koliko brzo zavisi od brzine uÄenja
- ako su nengativno korelisani teÅ¾ina se smanjuje
- sve se gleda kroz vreme a ne u jednoj iteraciji
- problem: ponovno ubacivanje ulaznih Å¡ablona dovodi do ekspoenencijalnog rasta teÅ¾ina, jaÄanje teÅ¾ina u +/- beskonaÄno
- reÅ¡enje: postaviti limite na vrednosti teÅ¾ina
- primer limita: nelinearni faktor zaboravljanja:
    - $\Delta u_{ki}(t) = \eta o_{k,p} z_{i,p} - \gamma o_{k,p}u_{k,i}(t-1)$
    - gde je $\gamma$ pozitivna konstanta koja kontroliÅ¡e umanjenje

    ### ?

---
## `36.` Kvantizacija vektora 1
- LVQ-1 klasterovanje
- PRESKOÄŒENO

--- 
## `37.` SamoorganizujuÄ‡e mape
- Self-organizing feature maps
- SOM
- razvio ih Kohonen u nameri da modelira karakteristike ljudskog celebralnog korteksa
- tehnika nenadgledanog uÄenja kod koga se vrÅ¡i viÅ¡edimenziono prosto preslikavanje u prostor niÅ¾e dimenzije, tako da se zadrÅ¾e veze iz viÅ¡ih dimenzija u niÅ¾im dimenzijama
- ako su taÄke bile blizu u viÅ¡im dimenzijama biÄ‡e blizu i u niÅ¾im
- podseÄ‡a na PCA
- metoda vrÅ¡i projekciju I-dimenzionog prostora u izlazni diskretni prostor (neki vid kompresije)
- izlazni postor je Äesto dvodimenziona mreÅ¾a vrednosti
- ideja je zadrÅ¾avanje topoloÅ¡ke strukture ulazno prostora
    - ako su dva podatka blizu u ulaznom prosoru biÄ‡e blizu i u izlaznom
    - sliÄne moÅ¾dane vrednosti aktiviraju bliske neurone

### StohastiÄko pravilo uÄenja
- zasnovano na kompetitivnoj strategiji uÄenja
- vrlo sliÄno LVQ-1 klasterovanju
- Ulazni podaci su povezani sa odgovarajuÄ‡im neuronima u mapi
    - mapa je obiÄno kvadratnog oblika
    - broj neurona je manji od broja trening podataka
    - u idealnom sluÄaju broj neurona je jednak broju nezavisnih trening primeraka
- ![](./imgs/som.png)
    - 2d reÅ¡etka neurona
    - svaki neuron je vektor teÅ¾ina
    - k redova i j kolona
    - i dimenzija posmatranih podataka
    - imamo 3D vektor atributa, k*j neurona gde svaki neuron ima dimenziju i (dimenziju ulaznih podataka)
    - svaki ulazni vektor se povezuje sa svakim neuronom
    - za svaki neuron moÅ¾emo izraÄunati sliÄnost sa ulaznim vrednostima, npr euklidsko rastojanje
- vektor teÅ¾ina za svaki neuron na poziviji (k,j) je inicijalno nasumiÄno podeÅ¡en
    - $w_{kj} = (w_{kj1}, w_{kj2}, ..., w_{KJI})$ 
- svaki ulazni podatak je povezan sa svakim neuronom iz mape
- prmetimo da je dimenzija vektora teÅ¾ina ista kao i dimenzija ulaznog podatka
- imamamo euklidsko rastojanje neurona i svih ulaza, gledamo koji neuron je najbliÅ¾i ulazu
- taj najbliÅ¾i neuron se naziva **pobedniÄki**
- pobedniÄki neuron i njemu bliski neuroni se aÅ¾uriraju kada se pojavi novi ulaz
- susednim neuronima se vrÅ¡i korekcija teÅ¾ina u skladu sa udeljenoÅ¡Ä‡u od pobedniÄkog
- idemo u smeru ulaznog vektora
- implicitno se poveÄ‡ava veza bliskih neurona, pa Ä‡e vektori teÅ¾ina biti meÄ‘usobno korelisani za bliske neurone
- to znaÄi da Ä‡e bliski neuroni reagovati na sliÄne nadraÅ¾aje iz spoljaÅ¡nje sredine
- nalik vizuelnom koreteksu i naÅ¡em reagovanju na boje 
    - vizuelni korteks se aktivira kada se javi sliÄna boja, ne nuÅ¾no skroz ista

- Primeri:
    - rasporeÄ‘ivanje tema na vikipediji
    - klasterovanje boja
    - ![](./imgs/som_primer.png)

- Primene
    - analiza slika
    - prepoznavanje zvuka
    - procesiranje signala
    - telekomunikacije
    - analiza vremenskih serija

- Pogodnosti
    - omoguÄ‡ava laku vizuelizaciju i interpretaciju
    - oblasti koje klasifikuju (kategoriÅ¡u) su vidljive na mapi